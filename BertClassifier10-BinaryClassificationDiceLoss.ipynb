{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c572f84e",
   "metadata": {},
   "source": [
    "# DONE:\n",
    "\n",
    "- x include non-Metaphor data and label\n",
    "\n",
    "- repeat experiments after sampling original sentences, not random sampling\n",
    "\n",
    "- fix the damn indentation on the accuracy\n",
    "\n",
    "- Try freezing some layers. Hopefully reduces training time (significantly)\n",
    "\n",
    "- FIXING BERT TOKENIZER TO REDEWIEDERGABE!!!\n",
    "\n",
    "- make use of cuda or mps nicer\n",
    "\n",
    "- increase freeze rate (Dropped performance slightly)\n",
    "\n",
    "- add additional dropout layer (not really sure if it helped)\n",
    "\n",
    "# NOW:\n",
    "\n",
    "- include loss and score plots\n",
    "\n",
    "# TODO:\n",
    "    \n",
    "- include F1-score in evaluation\n",
    "\n",
    "- x test F1-score loss function\n",
    "    - https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook\n",
    "    - not avaiable for mps yet!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bcdfdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "np.random.seed(3093453)\n",
    "sns.set(context=\"talk\", style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c8d64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Textstelle</th>\n",
       "      <th>Metapher</th>\n",
       "      <th>Kandidat</th>\n",
       "      <th>Nein</th>\n",
       "      <th>Metapher?</th>\n",
       "      <th>Fokus</th>\n",
       "      <th>Rahmen</th>\n",
       "      <th>Annotator</th>\n",
       "      <th>orig</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Der politische Körper verwendet in beiden Fäll...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>['Zähnen und Krallen', 'Zähnen und Krallen', n...</td>\n",
       "      <td>['der politische Körper', 'der politische Körp...</td>\n",
       "      <td>['B', 'K', 'A', 'GoldStandard']</td>\n",
       "      <td>\"Der politische Körper verwendet in beiden Fä...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Immer noch wird durch die protestantische Lehr...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>['B', 'K', 'A', 'GoldStandard']</td>\n",
       "      <td>\"Immer noch wird durch die protestantische Le...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kein Zweifel, schreibt Alb. Schaeffle, vorauss...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>['B', 'K', 'A', 'GoldStandard']</td>\n",
       "      <td>\"Kein Zweifel\", schreibt Alb. Schaeffle 1), v...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mit je weiterem Blick wir die Stoffwelt zu übe...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>[nan, 'Stoffwelt, verzwergt und entkleidet', n...</td>\n",
       "      <td>[nan, 'unser praktisches Ideal', nan, nan]</td>\n",
       "      <td>['B', 'K', 'A', 'GoldStandard']</td>\n",
       "      <td>\"Mit je weiterem Blick wir die Stoffwelt zu ü...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Solange das Menschengeschlecht seinen Zerstöre...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>['B', 'K', 'A', 'GoldStandard']</td>\n",
       "      <td>\"Solange das Menschengeschlecht seinen Zerstö...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>794</td>\n",
       "      <td>Sie hat durchweg Naturwissenschaft in dem von ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>['T', 'P', 'B', 'GoldStandard']</td>\n",
       "      <td>verlaufs; sie hat Naturforschung in dem von un...</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>795</td>\n",
       "      <td>Wenn wir uns ein Prinzip ausdenken und darauf ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>[nan, nan, 'verstellbare Puppen', nan]</td>\n",
       "      <td>[nan, nan, 'staatliche Menschenverhältnisse', ...</td>\n",
       "      <td>['P', 'K', 'B', 'GoldStandard']</td>\n",
       "      <td>wenn wir uns ein Prinzip denken und auf Grund ...</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>796</td>\n",
       "      <td>sieht man von dem Schimpfwort Rechtsphilosophi...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>['schwindsüchtig ist', nan, 'schwindsüchtig', ...</td>\n",
       "      <td>['daß eine Philosophie', nan, 'eine Philosophi...</td>\n",
       "      <td>['P', 'K', 'B', 'GoldStandard']</td>\n",
       "      <td>wenn wir von dem schlechten Worte »Rechtsphilo...</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>797</td>\n",
       "      <td>Die Macht der Regierung, die verschiedenen Mot...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>['P', 'B']</td>\n",
       "      <td>»Die Macht, die das Kabinett hat, auf die vers...</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>798</td>\n",
       "      <td>Über die Auswirkungen der Kreuzung auf die kör...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>['B', 'P']</td>\n",
       "      <td>Über die Wirkungen der Kreuzung auf die körper...</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3995 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                         Textstelle  Metapher  \\\n",
       "0         0  Der politische Körper verwendet in beiden Fäll...         3   \n",
       "1         1  Immer noch wird durch die protestantische Lehr...         0   \n",
       "2         2  Kein Zweifel, schreibt Alb. Schaeffle, vorauss...         0   \n",
       "3         3  Mit je weiterem Blick wir die Stoffwelt zu übe...         1   \n",
       "4         4  Solange das Menschengeschlecht seinen Zerstöre...         0   \n",
       "...     ...                                                ...       ...   \n",
       "3990    794  Sie hat durchweg Naturwissenschaft in dem von ...         0   \n",
       "3991    795  Wenn wir uns ein Prinzip ausdenken und darauf ...         1   \n",
       "3992    796  sieht man von dem Schimpfwort Rechtsphilosophi...         3   \n",
       "3993    797  Die Macht der Regierung, die verschiedenen Mot...         0   \n",
       "3994    798  Über die Auswirkungen der Kreuzung auf die kör...         0   \n",
       "\n",
       "      Kandidat  Nein          Metapher?  \\\n",
       "0            1     0           Metapher   \n",
       "1            4     0  Metaphernkandidat   \n",
       "2            4     0  Metaphernkandidat   \n",
       "3            3     0  Metaphernkandidat   \n",
       "4            4     0  Metaphernkandidat   \n",
       "...        ...   ...                ...   \n",
       "3990         4     0  Metaphernkandidat   \n",
       "3991         3     0  Metaphernkandidat   \n",
       "3992         1     0           Metapher   \n",
       "3993         2     0                NaN   \n",
       "3994         2     0                NaN   \n",
       "\n",
       "                                                  Fokus  \\\n",
       "0     ['Zähnen und Krallen', 'Zähnen und Krallen', n...   \n",
       "1                                  [nan, nan, nan, nan]   \n",
       "2                                  [nan, nan, nan, nan]   \n",
       "3     [nan, 'Stoffwelt, verzwergt und entkleidet', n...   \n",
       "4                                  [nan, nan, nan, nan]   \n",
       "...                                                 ...   \n",
       "3990                               [nan, nan, nan, nan]   \n",
       "3991             [nan, nan, 'verstellbare Puppen', nan]   \n",
       "3992  ['schwindsüchtig ist', nan, 'schwindsüchtig', ...   \n",
       "3993                                         [nan, nan]   \n",
       "3994                                         [nan, nan]   \n",
       "\n",
       "                                                 Rahmen  \\\n",
       "0     ['der politische Körper', 'der politische Körp...   \n",
       "1                                  [nan, nan, nan, nan]   \n",
       "2                                  [nan, nan, nan, nan]   \n",
       "3            [nan, 'unser praktisches Ideal', nan, nan]   \n",
       "4                                  [nan, nan, nan, nan]   \n",
       "...                                                 ...   \n",
       "3990                               [nan, nan, nan, nan]   \n",
       "3991  [nan, nan, 'staatliche Menschenverhältnisse', ...   \n",
       "3992  ['daß eine Philosophie', nan, 'eine Philosophi...   \n",
       "3993                                         [nan, nan]   \n",
       "3994                                         [nan, nan]   \n",
       "\n",
       "                            Annotator  \\\n",
       "0     ['B', 'K', 'A', 'GoldStandard']   \n",
       "1     ['B', 'K', 'A', 'GoldStandard']   \n",
       "2     ['B', 'K', 'A', 'GoldStandard']   \n",
       "3     ['B', 'K', 'A', 'GoldStandard']   \n",
       "4     ['B', 'K', 'A', 'GoldStandard']   \n",
       "...                               ...   \n",
       "3990  ['T', 'P', 'B', 'GoldStandard']   \n",
       "3991  ['P', 'K', 'B', 'GoldStandard']   \n",
       "3992  ['P', 'K', 'B', 'GoldStandard']   \n",
       "3993                       ['P', 'B']   \n",
       "3994                       ['B', 'P']   \n",
       "\n",
       "                                                   orig lang  \n",
       "0      \"Der politische Körper verwendet in beiden Fä...   de  \n",
       "1      \"Immer noch wird durch die protestantische Le...   de  \n",
       "2      \"Kein Zweifel\", schreibt Alb. Schaeffle 1), v...   de  \n",
       "3      \"Mit je weiterem Blick wir die Stoffwelt zu ü...   de  \n",
       "4      \"Solange das Menschengeschlecht seinen Zerstö...   de  \n",
       "...                                                 ...  ...  \n",
       "3990  verlaufs; sie hat Naturforschung in dem von un...   da  \n",
       "3991  wenn wir uns ein Prinzip denken und auf Grund ...   da  \n",
       "3992  wenn wir von dem schlechten Worte »Rechtsphilo...   da  \n",
       "3993  »Die Macht, die das Kabinett hat, auf die vers...   da  \n",
       "3994  Über die Wirkungen der Kreuzung auf die körper...   da  \n",
       "\n",
       "[3995 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "folder = \"clean+translated-data\"\n",
    "file = \"clean-de.csv\"\n",
    "path = \"/\".join( (cwd, folder, file) )\n",
    "\n",
    "df = pd.read_csv(path, index_col=0)\n",
    "df[\"lang\"] = \"de\"\n",
    "\n",
    "files = os.listdir(folder)\n",
    "files = [file for file in files if re.match(r'clean-[a-z]{2}-de.csv', file)]\n",
    "\n",
    "for file in files:\n",
    "    path = \"/\".join( (cwd, folder, file) )\n",
    "    data = pd.read_csv(path, index_col=0)\n",
    "    data[\"lang\"] = file[6:8]\n",
    "    \n",
    "    df = pd.concat([df, data])\n",
    "\n",
    "del(data)\n",
    "df.reset_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d7a1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Textstelle</th>\n",
       "      <th>Metapher</th>\n",
       "      <th>Kandidat</th>\n",
       "      <th>Nein</th>\n",
       "      <th>Metapher?</th>\n",
       "      <th>Fokus</th>\n",
       "      <th>Rahmen</th>\n",
       "      <th>Annotator</th>\n",
       "      <th>orig</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Eine sammlung von preisscliristenz Herausgegeb...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>Eine sammlung von preisscliristenz Herausgegeb...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Januar  veröffentlichten die Professoren Haeck...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>Januar 1900 veröffentlichten die Professoren H...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Unter den  Abhandlungen und Schriften, welche ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>Unter den 60 Abhandlungen und Schriften, welch...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In dem vorliegenden Sammelwerke werden sieben ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>In dem vorliegenden Sammelwerke werden sieben ...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Es folgt hier zunächst das Preisausschreiben, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>Es folgt hier zunächst das Preisausschreiben, ...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960</th>\n",
       "      <td>3960</td>\n",
       "      <td>In der Zeit des Humanismus und der Reformation...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>In der Zeit des Humanismus und der Reformation...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3961</th>\n",
       "      <td>3961</td>\n",
       "      <td>Den Mittelpunkt der Bildung stellten die alten...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>Den Mittelpunkt der Bildung stellten die alten...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962</th>\n",
       "      <td>3962</td>\n",
       "      <td>Jahrhunderts hat eine beständige Differenzieru...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>Jahrhunderts hat eine beständige Differenzieru...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3963</th>\n",
       "      <td>3963</td>\n",
       "      <td>Die Pädagogik der Neuzeit scheint davon wenig ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>Die Pädagogik der Neuzeit scheint davon wenig ...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>3964</td>\n",
       "      <td>Die Jugend in den Städten ist meistens unterer...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>Die Jugend in den Städten ist meistens unterer...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3965 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                         Textstelle  Metapher  \\\n",
       "0         0  Eine sammlung von preisscliristenz Herausgegeb...         0   \n",
       "1         1  Januar  veröffentlichten die Professoren Haeck...         0   \n",
       "2         2  Unter den  Abhandlungen und Schriften, welche ...         0   \n",
       "3         3  In dem vorliegenden Sammelwerke werden sieben ...         0   \n",
       "4         4  Es folgt hier zunächst das Preisausschreiben, ...         0   \n",
       "...     ...                                                ...       ...   \n",
       "3960   3960  In der Zeit des Humanismus und der Reformation...         0   \n",
       "3961   3961  Den Mittelpunkt der Bildung stellten die alten...         0   \n",
       "3962   3962  Jahrhunderts hat eine beständige Differenzieru...         0   \n",
       "3963   3963  Die Pädagogik der Neuzeit scheint davon wenig ...         0   \n",
       "3964   3964  Die Jugend in den Städten ist meistens unterer...         0   \n",
       "\n",
       "      Kandidat  Nein Metapher?  Fokus  Rahmen Annotator  \\\n",
       "0            0     1      Nein    NaN     NaN         X   \n",
       "1            0     1      Nein    NaN     NaN         X   \n",
       "2            0     1      Nein    NaN     NaN         X   \n",
       "3            0     1      Nein    NaN     NaN         X   \n",
       "4            0     1      Nein    NaN     NaN         X   \n",
       "...        ...   ...       ...    ...     ...       ...   \n",
       "3960         0     1      Nein    NaN     NaN         X   \n",
       "3961         0     1      Nein    NaN     NaN         X   \n",
       "3962         0     1      Nein    NaN     NaN         X   \n",
       "3963         0     1      Nein    NaN     NaN         X   \n",
       "3964         0     1      Nein    NaN     NaN         X   \n",
       "\n",
       "                                                   orig lang  \n",
       "0     Eine sammlung von preisscliristenz Herausgegeb...   de  \n",
       "1     Januar 1900 veröffentlichten die Professoren H...   de  \n",
       "2     Unter den 60 Abhandlungen und Schriften, welch...   de  \n",
       "3     In dem vorliegenden Sammelwerke werden sieben ...   de  \n",
       "4     Es folgt hier zunächst das Preisausschreiben, ...   de  \n",
       "...                                                 ...  ...  \n",
       "3960  In der Zeit des Humanismus und der Reformation...   de  \n",
       "3961  Den Mittelpunkt der Bildung stellten die alten...   de  \n",
       "3962  Jahrhunderts hat eine beständige Differenzieru...   de  \n",
       "3963  Die Pädagogik der Neuzeit scheint davon wenig ...   de  \n",
       "3964  Die Jugend in den Städten ist meistens unterer...   de  \n",
       "\n",
       "[3965 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "folder = \"clean+translated-data\"\n",
    "file = \"non-metaphor-clean-de.csv\"\n",
    "path = \"/\".join( (cwd, folder, file) )\n",
    "\n",
    "non = pd.read_csv(path)\n",
    "non[\"lang\"] = \"de\"\n",
    "non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5782989c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Textstelle</th>\n",
       "      <th>Metapher</th>\n",
       "      <th>Metaphernkandidat</th>\n",
       "      <th>Nein</th>\n",
       "      <th>Metapher?</th>\n",
       "      <th>Fokus</th>\n",
       "      <th>Rahmen</th>\n",
       "      <th>Annotator</th>\n",
       "      <th>orig</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Der politische Körper verwendet in beiden Fäll...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>['Zähnen und Krallen', 'Zähnen und Krallen', n...</td>\n",
       "      <td>['der politische Körper', 'der politische Körp...</td>\n",
       "      <td>['B', 'K', 'A', 'GoldStandard']</td>\n",
       "      <td>\"Der politische Körper verwendet in beiden Fä...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Immer noch wird durch die protestantische Lehr...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>['B', 'K', 'A', 'GoldStandard']</td>\n",
       "      <td>\"Immer noch wird durch die protestantische Le...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kein Zweifel, schreibt Alb. Schaeffle, vorauss...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>['B', 'K', 'A', 'GoldStandard']</td>\n",
       "      <td>\"Kein Zweifel\", schreibt Alb. Schaeffle 1), v...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mit je weiterem Blick wir die Stoffwelt zu übe...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>[nan, 'Stoffwelt, verzwergt und entkleidet', n...</td>\n",
       "      <td>[nan, 'unser praktisches Ideal', nan, nan]</td>\n",
       "      <td>['B', 'K', 'A', 'GoldStandard']</td>\n",
       "      <td>\"Mit je weiterem Blick wir die Stoffwelt zu ü...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Solange das Menschengeschlecht seinen Zerstöre...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "      <td>['B', 'K', 'A', 'GoldStandard']</td>\n",
       "      <td>\"Solange das Menschengeschlecht seinen Zerstö...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960</th>\n",
       "      <td>3960</td>\n",
       "      <td>In der Zeit des Humanismus und der Reformation...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>In der Zeit des Humanismus und der Reformation...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3961</th>\n",
       "      <td>3961</td>\n",
       "      <td>Den Mittelpunkt der Bildung stellten die alten...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>Den Mittelpunkt der Bildung stellten die alten...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962</th>\n",
       "      <td>3962</td>\n",
       "      <td>Jahrhunderts hat eine beständige Differenzieru...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>Jahrhunderts hat eine beständige Differenzieru...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3963</th>\n",
       "      <td>3963</td>\n",
       "      <td>Die Pädagogik der Neuzeit scheint davon wenig ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>Die Pädagogik der Neuzeit scheint davon wenig ...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>3964</td>\n",
       "      <td>Die Jugend in den Städten ist meistens unterer...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>Die Jugend in den Städten ist meistens unterer...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7960 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                         Textstelle  Metapher  \\\n",
       "0         0  Der politische Körper verwendet in beiden Fäll...         3   \n",
       "1         1  Immer noch wird durch die protestantische Lehr...         0   \n",
       "2         2  Kein Zweifel, schreibt Alb. Schaeffle, vorauss...         0   \n",
       "3         3  Mit je weiterem Blick wir die Stoffwelt zu übe...         1   \n",
       "4         4  Solange das Menschengeschlecht seinen Zerstöre...         0   \n",
       "...     ...                                                ...       ...   \n",
       "3960   3960  In der Zeit des Humanismus und der Reformation...         0   \n",
       "3961   3961  Den Mittelpunkt der Bildung stellten die alten...         0   \n",
       "3962   3962  Jahrhunderts hat eine beständige Differenzieru...         0   \n",
       "3963   3963  Die Pädagogik der Neuzeit scheint davon wenig ...         0   \n",
       "3964   3964  Die Jugend in den Städten ist meistens unterer...         0   \n",
       "\n",
       "      Metaphernkandidat  Nein          Metapher?  \\\n",
       "0                     1     0           Metapher   \n",
       "1                     4     0  Metaphernkandidat   \n",
       "2                     4     0  Metaphernkandidat   \n",
       "3                     3     0  Metaphernkandidat   \n",
       "4                     4     0  Metaphernkandidat   \n",
       "...                 ...   ...                ...   \n",
       "3960                  0     1               Nein   \n",
       "3961                  0     1               Nein   \n",
       "3962                  0     1               Nein   \n",
       "3963                  0     1               Nein   \n",
       "3964                  0     1               Nein   \n",
       "\n",
       "                                                  Fokus  \\\n",
       "0     ['Zähnen und Krallen', 'Zähnen und Krallen', n...   \n",
       "1                                  [nan, nan, nan, nan]   \n",
       "2                                  [nan, nan, nan, nan]   \n",
       "3     [nan, 'Stoffwelt, verzwergt und entkleidet', n...   \n",
       "4                                  [nan, nan, nan, nan]   \n",
       "...                                                 ...   \n",
       "3960                                                NaN   \n",
       "3961                                                NaN   \n",
       "3962                                                NaN   \n",
       "3963                                                NaN   \n",
       "3964                                                NaN   \n",
       "\n",
       "                                                 Rahmen  \\\n",
       "0     ['der politische Körper', 'der politische Körp...   \n",
       "1                                  [nan, nan, nan, nan]   \n",
       "2                                  [nan, nan, nan, nan]   \n",
       "3            [nan, 'unser praktisches Ideal', nan, nan]   \n",
       "4                                  [nan, nan, nan, nan]   \n",
       "...                                                 ...   \n",
       "3960                                                NaN   \n",
       "3961                                                NaN   \n",
       "3962                                                NaN   \n",
       "3963                                                NaN   \n",
       "3964                                                NaN   \n",
       "\n",
       "                            Annotator  \\\n",
       "0     ['B', 'K', 'A', 'GoldStandard']   \n",
       "1     ['B', 'K', 'A', 'GoldStandard']   \n",
       "2     ['B', 'K', 'A', 'GoldStandard']   \n",
       "3     ['B', 'K', 'A', 'GoldStandard']   \n",
       "4     ['B', 'K', 'A', 'GoldStandard']   \n",
       "...                               ...   \n",
       "3960                                X   \n",
       "3961                                X   \n",
       "3962                                X   \n",
       "3963                                X   \n",
       "3964                                X   \n",
       "\n",
       "                                                   orig lang  \n",
       "0      \"Der politische Körper verwendet in beiden Fä...   de  \n",
       "1      \"Immer noch wird durch die protestantische Le...   de  \n",
       "2      \"Kein Zweifel\", schreibt Alb. Schaeffle 1), v...   de  \n",
       "3      \"Mit je weiterem Blick wir die Stoffwelt zu ü...   de  \n",
       "4      \"Solange das Menschengeschlecht seinen Zerstö...   de  \n",
       "...                                                 ...  ...  \n",
       "3960  In der Zeit des Humanismus und der Reformation...   de  \n",
       "3961  Den Mittelpunkt der Bildung stellten die alten...   de  \n",
       "3962  Jahrhunderts hat eine beständige Differenzieru...   de  \n",
       "3963  Die Pädagogik der Neuzeit scheint davon wenig ...   de  \n",
       "3964  Die Jugend in den Städten ist meistens unterer...   de  \n",
       "\n",
       "[7960 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, non])\n",
    "df.reset_index(drop=True)\n",
    "df.rename(columns= {\"Kandidat\": \"Metaphernkandidat\"}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7841e1da",
   "metadata": {},
   "source": [
    "## Sentence ID\n",
    "\n",
    "We need to do this to make sure we dont have a german sentence in the train data\n",
    "... and a english version in the test data, which skewes the results\n",
    "\n",
    "(Essentially the model would just memorize seen points, rather than learn what a metaphor is)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbd90576",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = [\"Metapher\", \"Metaphernkandidat\", \"Nein\"]\n",
    "labels = dict(zip(range(3), labs))\n",
    "\n",
    "# impute missing labels with silver labels\n",
    "missing_lab = df[\"Metapher?\"].isnull()\n",
    "df.loc[missing_lab, \"Metapher?\"] = [labels[i] for i in df.loc[missing_lab, labs].to_numpy().argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cefb2b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "binary_labs = dict(zip(labs, [\"Metapher\", \"Nein\", \"Nein\"]))\n",
    "df[\"Metapher?\"] = df[\"Metapher?\"].map(binary_labs)\n",
    "vc = df[\"Metapher?\"].value_counts()\n",
    "plt.barh(vc.index, vc);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc7ab8",
   "metadata": {},
   "source": [
    "# BERT CLASSIFIER\n",
    "\n",
    "https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f\n",
    "\n",
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3eee607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"redewiedergabe/bert-base-historical-german-rw-cased\")\n",
    "\n",
    "# Later: non-Metaphor: 0, Candidate: 1, Metaphor: 2\n",
    "labs = [\"Nein\", \"Metapher\"]\n",
    "\n",
    "labels = dict(zip(labs, range(2)))\n",
    "labels\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        # gold and silver labels\n",
    "        \n",
    "        self.labels = [labels[label] for label in df[\"Metapher?\"]]\n",
    "        self.labels = df[labs].to_numpy().argmax(axis=1)\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['Textstelle']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d890c9",
   "metadata": {},
   "source": [
    "## Train test split:\n",
    "\n",
    "create a original-sentence id\n",
    "\n",
    "We need to do this to make sure we dont have a german sentence in the train data and a english version in the test \n",
    "data, which skewes the results\n",
    "\n",
    "(Essentially the model would just memorize seen points, rather than learn what a metaphor is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17b2c756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811 476 477\n",
      "6411 804 745\n"
     ]
    }
   ],
   "source": [
    "unique_sentences = df.orig.unique()\n",
    "\n",
    "sentence_id = [np.where(sentence == unique_sentences)[0].item() for sentence in df.orig]\n",
    "df[\"sentence_id\"] = sentence_id\n",
    "\n",
    "unique_sentence_ids = df.sentence_id.unique()\n",
    "n_unique_sentences = len(unique_sentence_ids)\n",
    "\n",
    "\n",
    "# randomize data before splitting\n",
    "sample = np.random.choice(unique_sentence_ids, n_unique_sentences, replace=False)\n",
    "\n",
    "# train/val/test split of original sentences\n",
    "train_sentence_ids,val_sentence_ids,test_sentence_ids = np.split(sample,\n",
    "                                                                 [int(.8*n_unique_sentences),\n",
    "                                                                  int(.9*n_unique_sentences)])\n",
    "\n",
    "print(len(train_sentence_ids),len(val_sentence_ids), len(test_sentence_ids))\n",
    "\n",
    "# train/val/test split rows\n",
    "df_train = df[np.isin(df.sentence_id, train_sentence_ids)]\n",
    "df_val   = df[np.isin(df.sentence_id, val_sentence_ids  )]\n",
    "df_test  = df[np.isin(df.sentence_id, test_sentence_ids )]\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2efcba32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vc = pd.Series([labels[label] for label in df_train[\"Metapher?\"]]).value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 8))\n",
    "plt.bar(vc.index, vc)\n",
    "plt.xticks(range(2),labs);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c56fb",
   "metadata": {},
   "source": [
    "## Building a Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e5f0e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at redewiedergabe/bert-base-historical-german-rw-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5, freeze = 0.8):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(\"redewiedergabe/bert-base-historical-german-rw-cased\")\n",
    "        \n",
    "        params = self.bert.parameters()\n",
    "        for i, param in enumerate(params):\n",
    "            if i > 197 * freeze:\n",
    "                continue\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        self.dropout1    = nn.Dropout(dropout)\n",
    "        self.linear1     = nn.Linear(768, 768)\n",
    "        self.activation1 = nn.ReLU(inplace=False)\n",
    "        self.dropout2    = nn.Dropout(dropout)\n",
    "        self.linear2     = nn.Linear(768, 1)\n",
    "        self.softmax     = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        \n",
    "        dropout_output1 = self.dropout1(pooled_output)\n",
    "        linear_output1 = self.linear1(dropout_output1)\n",
    "        activation1 = self.activation1(linear_output1)\n",
    "        \n",
    "        dropout_output2 = self.dropout2(activation1)\n",
    "        linear_output2 = self.linear2(dropout_output2)\n",
    "        \n",
    "        final_layer = self.softmax(linear_output2)\n",
    "\n",
    "        return final_layer\n",
    "    \n",
    "model = BertClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae579690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        #inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e26df395",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9923c021cd4b75af597fc18f8bbe1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 \n",
      "                | Train Loss: \t  0.070386942 \t                | Train Accuracy: \t  0.748089222\n",
      "                | Val Loss: \t  0.227 \t                | Val Accuracy: \t  0.708\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600d96308bb7421a89fbc6b8dbf725fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 \n",
      "                | Train Loss: \t  0.070374055 \t                | Train Accuracy: \t  0.748089222\n",
      "                | Val Loss: \t  0.227 \t                | Val Accuracy: \t  0.708\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97666d22aa5e427c80ca0162c766f729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 104>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m    102\u001b[0m LR \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m\n\u001b[0;32m--> 104\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     46\u001b[0m input_id \u001b[38;5;241m=\u001b[39m train_input[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# prediction\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m criterion(output, train_label)\n\u001b[1;32m     52\u001b[0m total_loss_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1186\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mBertClassifier.forward\u001b[0;34m(self, input_id, mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_id, mask):\n\u001b[0;32m---> 27\u001b[0m     _, pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     dropout_output1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(pooled_output)\n\u001b[1;32m     30\u001b[0m     linear_output1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(dropout_output1)\n",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1186\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1017\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1008\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1010\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1011\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1012\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1015\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1016\u001b[0m )\n\u001b[0;32m-> 1017\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1030\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1186\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:606\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    597\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    598\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    599\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    604\u001b[0m     )\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 606\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1186\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:493\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    483\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    492\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 493\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1186\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:423\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    415\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    422\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 423\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    433\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1186\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:361\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     attention_probs \u001b[38;5;241m=\u001b[39m attention_probs \u001b[38;5;241m*\u001b[39m head_mask\n\u001b[0;32m--> 361\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    364\u001b[0m new_context_layer_shape \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size,)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "    \n",
    "    # Basic setup: data, criterion, optimizer\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=8, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "    \n",
    "    criterion = DiceLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # make use of GPU acceleration if available\n",
    "    #if torch.backends.mps.is_available():\n",
    "    #    use_device = \"mps\"\n",
    "    #    print(\"Using M1 Chip! for training\")\n",
    "\n",
    "    #elif torch.cuda.is_available():\n",
    "    #    use_device = \"cuda\"\n",
    "    #    print(\"Using Graphics Card for training\")\n",
    "    #else:\n",
    "    use_device = \"cpu\"\n",
    "    #    print(\"Using regular CPU for training\")\n",
    "\n",
    "    device = torch.device(use_device)\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    # plot loss\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # training loop\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "                \n",
    "                # preprocessing\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "                \n",
    "                # prediction\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                # scores\n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "                \n",
    "                # actual training\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            train_losses.append(total_loss_train / len(train_data))\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "                \n",
    "                val_losses.append(total_loss_val / len(val_data))\n",
    "                \n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} \\n\\\n",
    "                | Train Loss: \\t {total_loss_train / len(train_data): .9f} \\t\\\n",
    "                | Train Accuracy: \\t {total_acc_train / len(train_data): .3f}\\n\\\n",
    "                | Val Loss: \\t {total_loss_val / len(val_data): .9f} \\t\\\n",
    "                | Val Accuracy: \\t {total_acc_val / len(val_data): .3f}')\n",
    "    \n",
    "    # plot losses\n",
    "    plt.figure(figsize=(13, 8))\n",
    "    plt.plot(train_losses, label=\"training loss\")\n",
    "    plt.plot(val_losses, label=\"validation loss\")\n",
    "    plt.legend();\n",
    "    plt.show();\n",
    "                  \n",
    "EPOCHS = 5\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9065a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa7181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    if torch.backends.mps.is_available():\n",
    "        use_device = \"mps\"\n",
    "        print(\"Using M1 Chip!\")\n",
    "\n",
    "    elif torch.cuda.is_available():\n",
    "        use_device = \"cuda\"\n",
    "        print(\"Using Graphics Card\")\n",
    "    else:\n",
    "        use_device = \"cpu\"\n",
    "        print(\"Using regular CPU\")\n",
    "        \n",
    "    device = torch.device(use_device)\n",
    "    model = model.to(use_device)\n",
    "\n",
    "\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "            \n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "            \n",
    "            output = model(input_id, mask)\n",
    "            \n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    \n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b28f5cb",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae73a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Dataset(df_test)\n",
    "\n",
    "batch_size=5\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS available\")\n",
    "\n",
    "y_test_prob = np.empty((len(df_test), 2), float)\n",
    "\n",
    "test_labels = np.zeros((len(df_test)), int)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "        i = 0\n",
    "        for test_input, test_label in test_dataloader:\n",
    "            \n",
    "            test_label = test_label.to(device)\n",
    "            test_labels[i*batch_size:(i+1)*batch_size] = test_label.cpu()\n",
    "            \n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "            \n",
    "            y_test_prob[i*batch_size:(i+1)*batch_size] = model(input_id, mask).cpu()\n",
    "            \n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_true = np.zeros((len(df_test), 2))\n",
    "y_test_true[np.arange(len(df_test)),test_labels] = 1\n",
    "y_test_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6756139",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2766b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = y_test_prob.argmax(axis=1)\n",
    "y_test_pred = np.zeros((len(df_test), 3))\n",
    "y_test_pred[np.arange(len(df_test)),test_preds] = 1\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b0044",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 8))\n",
    "for i in range(3):\n",
    "    prec, recall, _ = precision_recall_curve(y_test_true[:,i], y_test_prob[:,i])\n",
    "    avg_prec = average_precision_score(y_test_true[:,i], y_test_prob[:,i])\n",
    "    label = f\"{labs[i]}:  {avg_prec:.3f}\"\n",
    "    pr_display = PrecisionRecallDisplay(precision=prec, recall=recall).plot(ax=ax,label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(y_test_true.argmax(axis=1), y_test_prob.argmax(axis=1))\n",
    "confusion_matrix.index = labs\n",
    "confusion_matrix.index.name = \"true label\"\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d207be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"F1 scores:\\n\"+\"-\"*23)\n",
    "for i, lab in enumerate(labs):\n",
    "    f1 = f1_score(y_test_true[:,i], y_test_pred[:,i], average = \"binary\")\n",
    "    print(f\"{lab:>17}: {f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
