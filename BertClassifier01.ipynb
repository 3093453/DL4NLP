{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bcdfdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Textstelle</th>\n",
       "      <th>Metapher</th>\n",
       "      <th>Kandidat</th>\n",
       "      <th>Fokus</th>\n",
       "      <th>Rahmen</th>\n",
       "      <th>orig</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Der politische Körper verwendet in beiden Fäll...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Zähnen und Krallen</td>\n",
       "      <td>der politische Körper</td>\n",
       "      <td>\"Der politische Körper verwendet in beiden Fä...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Immer noch wird durch die protestantische Lehr...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Immer noch wird durch die protestantische Le...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kein Zweifel, schreibt Alb. Schaeffle, vorauss...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Kein Zweifel\", schreibt Alb. Schaeffle 1), v...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mit je weiterem Blick wir die Stoffwelt zu übe...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Stoffwelt, verzwergt und entkleidet</td>\n",
       "      <td>unser praktisches Ideal</td>\n",
       "      <td>\"Mit je weiterem Blick wir die Stoffwelt zu ü...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Solange das Menschengeschlecht seinen Zerstöre...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Solange das Menschengeschlecht seinen Zerstö...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>794</td>\n",
       "      <td>Sie hat durchweg Naturwissenschaft in dem von ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>verlaufs; sie hat Naturforschung in dem von un...</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>795</td>\n",
       "      <td>Wenn wir uns ein Prinzip ausdenken und darauf ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>verstellbare Puppen</td>\n",
       "      <td>staatliche Menschenverhältnisse</td>\n",
       "      <td>wenn wir uns ein Prinzip denken und auf Grund ...</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>796</td>\n",
       "      <td>sieht man von dem Schimpfwort Rechtsphilosophi...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>schwindsüchtig ist</td>\n",
       "      <td>daß eine Philosophie</td>\n",
       "      <td>wenn wir von dem schlechten Worte »Rechtsphilo...</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>797</td>\n",
       "      <td>Die Macht der Regierung, die verschiedenen Mot...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>»Die Macht, die das Kabinett hat, auf die vers...</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>798</td>\n",
       "      <td>Über die Auswirkungen der Kreuzung auf die kör...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Über die Wirkungen der Kreuzung auf die körper...</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3995 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                         Textstelle  Metapher  \\\n",
       "0         0  Der politische Körper verwendet in beiden Fäll...         2   \n",
       "1         1  Immer noch wird durch die protestantische Lehr...         0   \n",
       "2         2  Kein Zweifel, schreibt Alb. Schaeffle, vorauss...         0   \n",
       "3         3  Mit je weiterem Blick wir die Stoffwelt zu übe...         1   \n",
       "4         4  Solange das Menschengeschlecht seinen Zerstöre...         0   \n",
       "...     ...                                                ...       ...   \n",
       "3990    794  Sie hat durchweg Naturwissenschaft in dem von ...         0   \n",
       "3991    795  Wenn wir uns ein Prinzip ausdenken und darauf ...         1   \n",
       "3992    796  sieht man von dem Schimpfwort Rechtsphilosophi...         2   \n",
       "3993    797  Die Macht der Regierung, die verschiedenen Mot...         0   \n",
       "3994    798  Über die Auswirkungen der Kreuzung auf die kör...         0   \n",
       "\n",
       "      Kandidat                                Fokus  \\\n",
       "0            1                   Zähnen und Krallen   \n",
       "1            3                                  NaN   \n",
       "2            3                                  NaN   \n",
       "3            2  Stoffwelt, verzwergt und entkleidet   \n",
       "4            3                                  NaN   \n",
       "...        ...                                  ...   \n",
       "3990         3                                  NaN   \n",
       "3991         2                  verstellbare Puppen   \n",
       "3992         1                   schwindsüchtig ist   \n",
       "3993         2                                  NaN   \n",
       "3994         2                                  NaN   \n",
       "\n",
       "                               Rahmen  \\\n",
       "0               der politische Körper   \n",
       "1                                 NaN   \n",
       "2                                 NaN   \n",
       "3             unser praktisches Ideal   \n",
       "4                                 NaN   \n",
       "...                               ...   \n",
       "3990                              NaN   \n",
       "3991  staatliche Menschenverhältnisse   \n",
       "3992             daß eine Philosophie   \n",
       "3993                              NaN   \n",
       "3994                              NaN   \n",
       "\n",
       "                                                   orig lang  \n",
       "0      \"Der politische Körper verwendet in beiden Fä...   de  \n",
       "1      \"Immer noch wird durch die protestantische Le...   de  \n",
       "2      \"Kein Zweifel\", schreibt Alb. Schaeffle 1), v...   de  \n",
       "3      \"Mit je weiterem Blick wir die Stoffwelt zu ü...   de  \n",
       "4      \"Solange das Menschengeschlecht seinen Zerstö...   de  \n",
       "...                                                 ...  ...  \n",
       "3990  verlaufs; sie hat Naturforschung in dem von un...   da  \n",
       "3991  wenn wir uns ein Prinzip denken und auf Grund ...   da  \n",
       "3992  wenn wir von dem schlechten Worte »Rechtsphilo...   da  \n",
       "3993  »Die Macht, die das Kabinett hat, auf die vers...   da  \n",
       "3994  Über die Wirkungen der Kreuzung auf die körper...   da  \n",
       "\n",
       "[3995 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "np.random.seed(3093453)\n",
    "sns.set(context=\"talk\", style=\"darkgrid\")\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "folder = \"clean+translated-data\"\n",
    "file = \"clean-de.csv\"\n",
    "path = \"/\".join( (cwd, folder, file) )\n",
    "\n",
    "df = pd.read_csv(path, index_col=0)\n",
    "df[\"lang\"] = \"de\"\n",
    "\n",
    "files = os.listdir(folder)\n",
    "files = [file for file in files if re.match(r'clean-[a-z]{2}-de.csv', file)]\n",
    "\n",
    "for file in files:\n",
    "    path = \"/\".join( (cwd, folder, file) )\n",
    "    data = pd.read_csv(path, index_col=0)\n",
    "    data[\"lang\"] = file[6:8]\n",
    "    \n",
    "    df = pd.concat([df, data])\n",
    "\n",
    "del(data)\n",
    "df.reset_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af645b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.loc[(df.lang==\"de\"), [\"Metapher\", \"Kandidat\"]].sum(axis=1).hist(bins=np.arange(0,9)+0.5)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab28eb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Textstelle</th>\n",
       "      <th>Metapher</th>\n",
       "      <th>Kandidat</th>\n",
       "      <th>Fokus</th>\n",
       "      <th>Rahmen</th>\n",
       "      <th>orig</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>Bei Beobach tung solchen moralischen Wertes ka...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>das Horoskop stellen</td>\n",
       "      <td>einer Nation</td>\n",
       "      <td>Bei Beobachtung solchen moralischen Wertes ka...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>Die Zellen verschmelzen miteinander.</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Die Zellen verschmelzen miteinander.</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>Ein ganz ähnliches Schicksal war alsdann den R...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>die Zügel</td>\n",
       "      <td>der Weltherrschaft</td>\n",
       "      <td>Ein ganz ähnliches Schicksal war alsdann den ...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>Es waren also mörderische Kriege, die wohl ims...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Es waren also mörderische Kriege, die wohl im...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>Wenn man die zahllosen Schwierigkeiten bedenkt...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>schreiendes</td>\n",
       "      <td>Unrecht</td>\n",
       "      <td>Wenn man die zahllosen Schwierigkeiten bedenk...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>376</td>\n",
       "      <td>Allerdings hat auch hier der vordringende Wahr...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Schrauben und Fugen</td>\n",
       "      <td>des alten ehrwürdigen Dogmengebäudes</td>\n",
       "      <td>30\\tAllerdings hat auch hier der vordringende ...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>504</td>\n",
       "      <td>Die Organisation, wie das natürlich ist, geht ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Die Organisation, wie das natürlich ist, geht ...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>515</td>\n",
       "      <td>Die Worte, die man braucht, sind dann nicht Mi...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Pflugscharen zur Lockerung</td>\n",
       "      <td>Die Worte</td>\n",
       "      <td>Die Worte, die man braucht, sind dann nicht Mi...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>589</td>\n",
       "      <td>Hier im Leben aber, in dem, was für Platon das...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>pulsiert</td>\n",
       "      <td>die wirkliche Realität</td>\n",
       "      <td>Hier im Leben aber, in dem, was für Platon das...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>786</td>\n",
       "      <td>So band er das Geschlecht von heute an das ver...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>starrt in das Dunkel</td>\n",
       "      <td>der Vergangenheit2</td>\n",
       "      <td>[8]: So band er das Geschlecht von heute an da...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                         Textstelle  Metapher  \\\n",
       "36      36  Bei Beobach tung solchen moralischen Wertes ka...         8   \n",
       "112    112               Die Zellen verschmelzen miteinander.         0   \n",
       "141    141  Ein ganz ähnliches Schicksal war alsdann den R...         5   \n",
       "170    170  Es waren also mörderische Kriege, die wohl ims...         0   \n",
       "308    308  Wenn man die zahllosen Schwierigkeiten bedenkt...         1   \n",
       "376    376  Allerdings hat auch hier der vordringende Wahr...         6   \n",
       "504    504  Die Organisation, wie das natürlich ist, geht ...         1   \n",
       "515    515  Die Worte, die man braucht, sind dann nicht Mi...         6   \n",
       "589    589  Hier im Leben aber, in dem, was für Platon das...         4   \n",
       "786    786  So band er das Geschlecht von heute an das ver...         4   \n",
       "\n",
       "     Kandidat                       Fokus  \\\n",
       "36          0        das Horoskop stellen   \n",
       "112         8                         NaN   \n",
       "141         1                   die Zügel   \n",
       "170         6                         NaN   \n",
       "308         6                 schreiendes   \n",
       "376         1         Schrauben und Fugen   \n",
       "504         5                         NaN   \n",
       "515         0  Pflugscharen zur Lockerung   \n",
       "589         2                    pulsiert   \n",
       "786         3        starrt in das Dunkel   \n",
       "\n",
       "                                   Rahmen  \\\n",
       "36                           einer Nation   \n",
       "112                                   NaN   \n",
       "141                    der Weltherrschaft   \n",
       "170                                   NaN   \n",
       "308                               Unrecht   \n",
       "376  des alten ehrwürdigen Dogmengebäudes   \n",
       "504                                   NaN   \n",
       "515                             Die Worte   \n",
       "589                die wirkliche Realität   \n",
       "786                    der Vergangenheit2   \n",
       "\n",
       "                                                  orig lang  \n",
       "36    Bei Beobachtung solchen moralischen Wertes ka...   de  \n",
       "112               Die Zellen verschmelzen miteinander.   de  \n",
       "141   Ein ganz ähnliches Schicksal war alsdann den ...   de  \n",
       "170   Es waren also mörderische Kriege, die wohl im...   de  \n",
       "308   Wenn man die zahllosen Schwierigkeiten bedenk...   de  \n",
       "376  30\\tAllerdings hat auch hier der vordringende ...   de  \n",
       "504  Die Organisation, wie das natürlich ist, geht ...   de  \n",
       "515  Die Worte, die man braucht, sind dann nicht Mi...   de  \n",
       "589  Hier im Leben aber, in dem, was für Platon das...   de  \n",
       "786  [8]: So band er das Geschlecht von heute an da...   de  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.lang==\"de\")][df.loc[(df.lang==\"de\"), [\"Metapher\", \"Kandidat\"]].sum(axis=1) > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3a1189",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.lang==\"de\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf075d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7221526908635795"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.loc[(df.lang==\"de\"), [\"Metapher\", \"Kandidat\"]].to_numpy().argmax(axis=1)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc7ab8",
   "metadata": {},
   "source": [
    "# BERT CLASSIFIER\n",
    "\n",
    "https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f\n",
    "\n",
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3eee607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# Later: non-Metaphor: 0, Candidate: 1, Metaphor: 2\n",
    "labels = {'business':0,\n",
    "          'entertainment':1,\n",
    "          'sport':2,\n",
    "          'tech':3,\n",
    "          'politics':4\n",
    "          }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        # binary silver labels for now\n",
    "        self.labels = df.loc[(df.lang==\"de\"), [\"Metapher\", \"Kandidat\"]].to_numpy().argmax(axis=1)\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['Textstelle']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d890c9",
   "metadata": {},
   "source": [
    "## Train test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5003ec20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639 80 80\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c56fb",
   "metadata": {},
   "source": [
    "## Building a Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5f0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(\"redewiedergabe/bert-base-historical-german-rw-cased\")\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.softmax(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e26df395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at redewiedergabe/bert-base-historical-german-rw-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available\n",
      "mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [02:43<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.313                 | Train Accuracy:  0.696                 | Val Loss:  0.299                 | Val Accuracy:  0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [02:34<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.299                 | Train Accuracy:  0.718                 | Val Loss:  0.295                 | Val Accuracy:  0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [02:34<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.297                 | Train Accuracy:  0.718                 | Val Loss:  0.296                 | Val Accuracy:  0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [02:33<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.297                 | Train Accuracy:  0.718                 | Val Loss:  0.293                 | Val Accuracy:  0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [02:34<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.292                 | Train Accuracy:  0.723                 | Val Loss:  0.293                 | Val Accuracy:  0.725\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"MPS available\")\n",
    "    print(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "        \n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "            \n",
    "    if torch.backends.mps.is_available():\n",
    "        model = model.to(\"mps\")\n",
    "        criterion = criterion.to(\"mps\")\n",
    "        \n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  \n",
    "EPOCHS = 5\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcfa7181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available\n",
      "Test Accuracy:  0.750\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"MPS available\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "        \n",
    "    if torch.backends.mps.is_available():\n",
    "        model = model.to(\"mps\")\n",
    "    \n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "            \n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "            \n",
    "            output = model(input_id, mask)\n",
    "            \n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    \n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d9ba3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[[\"Metapher\", \"Kandidat\"]].to_numpy().argmax(axis=1).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
