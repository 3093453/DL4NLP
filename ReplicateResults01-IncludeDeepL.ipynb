{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe6bad2",
   "metadata": {},
   "source": [
    "Now we recreate the results after oversampling by translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b37f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ast\n",
    "import copy\n",
    "#import csv\n",
    "#import glob\n",
    "#import json\n",
    "import random\n",
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "import deepl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from transformers import (AutoConfig, AutoModelForSequenceClassification,\n",
    "                          AutoTokenizer, BertForSequenceClassification,\n",
    "                          BertModel, Trainer, TrainingArguments)\n",
    "\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.bert.modeling_bert import *\n",
    "from transformers.utils.dummy_tf_objects import TFDPRQuestionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b51752",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.getcwd()\n",
    "DATA_PATH = '/data'\n",
    "MODEL_PATH = '/model'\n",
    "RESULTS_PATH = '/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0326a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this parameter is set on true, oversampling will be performed on the dataframe\n",
    "oversample_dataframe = True\n",
    "\n",
    "# For the use of the Deepl API (is used to oversample the data set), a Deepl Authentication Key is needed\n",
    "# To obtain such a key, a free trial can be started on the following page: https://www.deepl.com/docs-api/\n",
    "# When 500.000 characters have been translated, a credit card is needed to start a real abonnement and to access the API\n",
    "deepl_auth_key = 'ec362cc6-2825-caaf-5273-8600eb06895e:fx'\n",
    "\n",
    "# This parameter specifies the number of iterations after which the intermediate result of the dataframe should be stored repeatedly\n",
    "backup_oversampled_dataframe_after_rows = 40\n",
    "\n",
    "def set_default_staerkegrad_df(df):\n",
    "  \"\"\" \n",
    "  set_default_staerkegrad accepts a dataframe as input. Checks if there is a column named \"Staerkegrad\"\n",
    "  and if there is inserts into empty fields in that column the mostly used value from the column.\n",
    "\n",
    "  :param df: a pandas dataframe\n",
    "  :return: a pandas dataframe, where for every undefined entry in the column \"Staerkgegrad\" the most common value from all rows is set. If there is no such column in the input dataframe, the input dataframe is returned.  \n",
    "  \"\"\"\n",
    "  if ('Stärkegrad (A, B, C)' not in df.columns):\n",
    "    print('[set_default_staerkegrad_df]: Given dataframe does not consist of a column \"Staerkegrad\"!')\n",
    "    return df\n",
    "  else:\n",
    "    most_used_staerkegrad = df['Stärkegrad (A, B, C)'].value_counts().index[0]\n",
    "    df.fillna(value={'Stärkegrad (A, B, C)': most_used_staerkegrad})\n",
    "    return df\n",
    "\n",
    "def translate(text, target_language):\n",
    "  \"\"\"\n",
    "  translate translates the input text into the target language.\n",
    "\n",
    "  :param text: the text to be translated\n",
    "  :param target_language: the deepl target language expression, examples are 'DE' or 'EN-US'\n",
    "  :return: a string, the translation of :param text into the :param target_language\n",
    "  \"\"\"\n",
    "  translator = deepl.Translator(deepl_auth_key) \n",
    "  result = translator.translate_text(text, target_lang=target_language) \n",
    "  translated_text = result.text\n",
    "  return translated_text\n",
    "\n",
    "def translate_into_english_and_back(text):\n",
    "  \"\"\"\n",
    "  translate_into_english_and_back translates the input text into english and then into German.\n",
    "\n",
    "  :param text: the text to be translated\n",
    "  :return: a string. Returned is the result from translating :param text into englisch and after that into German.\n",
    "  \"\"\"\n",
    "  translator = deepl.Translator(deepl_auth_key) \n",
    "  result_eng = translator.translate_text(text, target_lang='EN-US')\n",
    "  result_ger = translator.translate_text(result_eng.text, target_lang='DE')\n",
    "  return result_ger.text\n",
    "\n",
    "def translate_into_target_language_and_back(text, target_language):\n",
    "  \"\"\"\n",
    "  translate_into_target_language_and_back translates the input text into the given target_language and then into German.\n",
    "\n",
    "  :param text: the text to be translated\n",
    "  :param target_language: the language\n",
    "  :return: a string. Returned is the result from translating :param text into :param target_language and then into German. \n",
    "  \"\"\"\n",
    "  translator = deepl.Translator(deepl_auth_key) \n",
    "  result_eng = translator.translate_text(text, target_lang=target_language)\n",
    "  result_ger = translator.translate_text(result_eng.text, target_lang='DE')\n",
    "  return result_ger.text\n",
    "\n",
    "def oversample_dataframe(df):\n",
    "  \"\"\"\n",
    "  Accepts a dataframe and returns the dataframe with oversampled data. The function was written for the known dataset of the Goldstandard. \n",
    "  In detail, every Textstelle (from metaphors only) from the input dataframe is taken, translated into four languages (english, spanish, czech and polish) and back into German.\n",
    "  By this way, for each Textstelle from :param df, four new texts are generated and added to the output dataframe. \n",
    "\n",
    "  :param df: a pandas dataframe. \n",
    "  :return: a pandas dataframe. In the output dataframe, four columns have been added, in which the different back and forth translated German texts are. \n",
    "  \"\"\"\n",
    "  # Before the oversampling, the counts of unique rows in the input df and of rows which are metaphors are printed\n",
    "  print('Ausprägungen und Anzahl Werte für gold_standard_df vor Oversampling:', df['Metapher?'].value_counts())\n",
    "  print('Metaphern im gold_standard_df vor Oversampling', df['Metapher?'].value_counts().Metapher)\n",
    "\n",
    "  # To backup interim results, this counter is initialized\n",
    "  count = 1\n",
    "\n",
    "  # To keep count of successfully added translated metaphor texts, the following counter is initialized\n",
    "  count_successfully_added_metaphor_texts = 0\n",
    "\n",
    "  # Split the input dataframe into two dataframes, one containing only metaphors and one with only not metaphors\n",
    "  only_metaphor_df = df[(df['Metapher?'] == 'Metapher')]\n",
    "  no_metaphors_df = df[(df['Metapher?'] != 'Metapher')]\n",
    "\n",
    "  # To the dataframe containing only metaphors, add four columns where the newly generated texts can be inserted to\n",
    "  only_metaphor_df['Synonym (aus Englischem)'] = \"\"\n",
    "  only_metaphor_df['Synonym (aus Spanischem)'] = \"\"\n",
    "  only_metaphor_df['Synonym (aus Tchechischem)'] = \"\"\n",
    "  only_metaphor_df['Synonym (aus Polnischem)'] = \"\"\n",
    "  \n",
    "  # Loop over all rows in the dataframe containing only metaphors and translate the text back and forth and insert the German result in the correct dataframe cell\n",
    "  for index, row in only_metaphor_df.iterrows():\n",
    "    text = row['Textstelle']\n",
    "    row['Synonym (aus Englischem)'] = translate_into_target_language_and_back(text, 'EN-US')\n",
    "    row['Synonym (aus Spanischem)'] = translate_into_target_language_and_back(text, 'ES')\n",
    "    row['Synonym (aus Tchechischem)'] = translate_into_target_language_and_back(text, 'CS')\n",
    "    row['Synonym (aus Polnischem)'] = translate_into_target_language_and_back(text, 'PL')\n",
    "    count_successfully_added_metaphor_texts += 4\n",
    "    print('working, count:', count)\n",
    "\n",
    "    # Backup interim results of the dataframe as csv files every 'backup_oversampled_dataframe_after_rows' iterations\n",
    "    if (count % backup_oversampled_dataframe_after_rows == 0): \n",
    "      only_metaphor_df.to_csv('only_metaphor_df_four_languages_backup_iteration_' + str(count) + '.csv', index=False)\n",
    "\n",
    "    # Increase counter\n",
    "    count+=1\n",
    "\n",
    "  # After the for loop, the two dataframes only metaphor and not metaphors need to get concatenated again\n",
    "  oversampled_data_df = only_metaphor_df.append(no_metaphors_df)\n",
    "\n",
    "  # After the oversampling, print the counts of unique rows in the oversampled dataframe and of rows which are metaphors again to get an overview on the results of the data augmentation \n",
    "  print('Ausprägungen und Anzahl Werte für gold_standard_df nach Oversampling:', oversampled_data_df['Metapher?'].value_counts())\n",
    "  print('Metaphern im gold_standard_df nach Oversampling', oversampled_data_df['Metapher?'].value_counts().Metapher + count_successfully_added_metaphor_texts)\n",
    "\n",
    "  return oversampled_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46436df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_settings(path, annotators, epochs, folds, model_type, oversampling, smote, comment):\n",
    "  \"\"\"\n",
    "  Saves the given settings to a text file at a given path\n",
    "  :param path: the path to output the text file to\n",
    "  :param annotators: The annotators to save \n",
    "  :param epochs: The number of epochs to save \n",
    "  :param folds: The number of folds to save \n",
    "  :param model_type: The model type to save \n",
    "  :param oversampling: The boolean if oversampling is activated \n",
    "  :param smote: The K for SMOTE to save \n",
    "  :param comment: A free comment to save in the text file\n",
    "  \"\"\"  \n",
    "  \n",
    "  lines = []\n",
    "  lines.append('Annotators: ' + ', '.join(annotators))\n",
    "  lines.append('Epochs: ' + str(epochs))\n",
    "  lines.append('Folds: ' + str(folds))\n",
    "  lines.append('Model Type: ' + model_type)\n",
    "  lines.append('Oversampling: ' + (\"On\" if oversampling else \"Off\"))\n",
    "  lines.append('SMOTE: ' + ((\"On (K=\"+str(smote)+\")\") if smote>0 else \"Off\"))\n",
    "  lines.append('Comment: ' + comment)\n",
    "\n",
    "  with open(path+'/settings.txt', 'w') as f: \n",
    "    f.write('\\n'.join(lines))\n",
    "\n",
    "  print(\"Settings saved to\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f75c3136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading annotated data for individual annotators\n",
    "raw_df = pd.read_csv(ROOT_PATH + DATA_PATH + '/Annotationen-Stufe-2.txt', index_col=0)\n",
    "# Drop rows where Textstelle is NaN\n",
    "index_names = raw_df[raw_df['Textstelle'].isnull()].index\n",
    "raw_df.drop(index_names, inplace=True)\n",
    "# setting the Stärkegrad if not present\n",
    "raw_df = set_default_staerkegrad_df(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c9043e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ausprägungen und Anzahl Werte für gold_standard_df vor Oversampling: Metaphernkandidat    529\n",
      "Metapher             129\n",
      "Name: Metapher?, dtype: int64\n",
      "Metaphern im gold_standard_df vor Oversampling 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j4/qmf6qmvd1gv0nctgx3m6jm3r0000gn/T/ipykernel_26536/3817409328.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  only_metaphor_df['Synonym (aus Englischem)'] = \"\"\n",
      "/var/folders/j4/qmf6qmvd1gv0nctgx3m6jm3r0000gn/T/ipykernel_26536/3817409328.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  only_metaphor_df['Synonym (aus Spanischem)'] = \"\"\n",
      "/var/folders/j4/qmf6qmvd1gv0nctgx3m6jm3r0000gn/T/ipykernel_26536/3817409328.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  only_metaphor_df['Synonym (aus Tchechischem)'] = \"\"\n",
      "/var/folders/j4/qmf6qmvd1gv0nctgx3m6jm3r0000gn/T/ipykernel_26536/3817409328.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  only_metaphor_df['Synonym (aus Polnischem)'] = \"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working, count: 1\n",
      "working, count: 2\n",
      "working, count: 3\n",
      "working, count: 4\n",
      "working, count: 5\n",
      "working, count: 6\n",
      "working, count: 7\n",
      "working, count: 8\n",
      "working, count: 9\n",
      "working, count: 10\n",
      "working, count: 11\n",
      "working, count: 12\n",
      "working, count: 13\n",
      "working, count: 14\n",
      "working, count: 15\n",
      "working, count: 16\n",
      "working, count: 17\n",
      "working, count: 18\n",
      "working, count: 19\n",
      "working, count: 20\n",
      "working, count: 21\n",
      "working, count: 22\n",
      "working, count: 23\n",
      "working, count: 24\n",
      "working, count: 25\n",
      "working, count: 26\n",
      "working, count: 27\n",
      "working, count: 28\n",
      "working, count: 29\n",
      "working, count: 30\n",
      "working, count: 31\n",
      "working, count: 32\n",
      "working, count: 33\n",
      "working, count: 34\n",
      "working, count: 35\n",
      "working, count: 36\n",
      "working, count: 37\n",
      "working, count: 38\n",
      "working, count: 39\n",
      "working, count: 40\n",
      "working, count: 41\n",
      "working, count: 42\n",
      "working, count: 43\n",
      "working, count: 44\n",
      "working, count: 45\n",
      "working, count: 46\n",
      "working, count: 47\n",
      "working, count: 48\n",
      "working, count: 49\n",
      "working, count: 50\n",
      "working, count: 51\n",
      "working, count: 52\n",
      "working, count: 53\n",
      "working, count: 54\n",
      "working, count: 55\n",
      "working, count: 56\n",
      "working, count: 57\n",
      "working, count: 58\n",
      "working, count: 59\n",
      "working, count: 60\n",
      "working, count: 61\n",
      "working, count: 62\n",
      "working, count: 63\n",
      "working, count: 64\n",
      "working, count: 65\n",
      "working, count: 66\n",
      "working, count: 67\n",
      "working, count: 68\n",
      "working, count: 69\n",
      "working, count: 70\n",
      "working, count: 71\n",
      "working, count: 72\n",
      "working, count: 73\n",
      "working, count: 74\n",
      "working, count: 75\n",
      "working, count: 76\n",
      "working, count: 77\n",
      "working, count: 78\n",
      "working, count: 79\n",
      "working, count: 80\n",
      "working, count: 81\n",
      "working, count: 82\n",
      "working, count: 83\n",
      "working, count: 84\n",
      "working, count: 85\n",
      "working, count: 86\n",
      "working, count: 87\n",
      "working, count: 88\n",
      "working, count: 89\n",
      "working, count: 90\n",
      "working, count: 91\n",
      "working, count: 92\n",
      "working, count: 93\n",
      "working, count: 94\n",
      "working, count: 95\n",
      "working, count: 96\n",
      "working, count: 97\n",
      "working, count: 98\n",
      "working, count: 99\n",
      "working, count: 100\n",
      "working, count: 101\n",
      "working, count: 102\n",
      "working, count: 103\n",
      "working, count: 104\n",
      "working, count: 105\n",
      "working, count: 106\n",
      "working, count: 107\n",
      "working, count: 108\n",
      "working, count: 109\n",
      "working, count: 110\n",
      "working, count: 111\n",
      "working, count: 112\n",
      "working, count: 113\n",
      "working, count: 114\n",
      "working, count: 115\n",
      "working, count: 116\n",
      "working, count: 117\n",
      "working, count: 118\n",
      "working, count: 119\n",
      "working, count: 120\n",
      "working, count: 121\n",
      "working, count: 122\n",
      "working, count: 123\n",
      "working, count: 124\n",
      "working, count: 125\n",
      "working, count: 126\n",
      "working, count: 127\n",
      "working, count: 128\n",
      "working, count: 129\n",
      "Ausprägungen und Anzahl Werte für gold_standard_df nach Oversampling: Metaphernkandidat    529\n",
      "Metapher             129\n",
      "Name: Metapher?, dtype: int64\n",
      "Metaphern im gold_standard_df nach Oversampling 645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j4/qmf6qmvd1gv0nctgx3m6jm3r0000gn/T/ipykernel_26536/3817409328.py:113: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  oversampled_data_df = only_metaphor_df.append(no_metaphors_df)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seite</th>\n",
       "      <th>Textstelle</th>\n",
       "      <th>Metapher?</th>\n",
       "      <th>Fokus</th>\n",
       "      <th>Rahmen</th>\n",
       "      <th>Stärkegrad (A, B, C)</th>\n",
       "      <th>Begründung/Kommentar</th>\n",
       "      <th>Annotator</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Semantikerweiterung?</th>\n",
       "      <th>Unersetzlich?</th>\n",
       "      <th>sprachlich irregulär?</th>\n",
       "      <th>pointiert?</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bei Beobachtung solchen moralischen Wertes ka...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>das Horoskop stellen</td>\n",
       "      <td>einer Nation</td>\n",
       "      <td>B</td>\n",
       "      <td>Horoskop stellen - bezogen auf Nationen ist da...</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Diese wolle die bittere Auslese, ohne die auc...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>bittere</td>\n",
       "      <td>Auslese</td>\n",
       "      <td>A</td>\n",
       "      <td>Unauffällig, aber doch metaphorisch: Dass eine...</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wenn es dem Verfasser gelungen ist, ein gesic...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>ein gesichertes Fundament und die ersten Pfeil...</td>\n",
       "      <td>die Lösung der hier zur Bearbeitung gestellten...</td>\n",
       "      <td>A</td>\n",
       "      <td>Bruch, Fokus nicht ohne Bedeutungsverlust erse...</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Man kann vielmehr in das Getriebe des gesells...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>Leuchte der Wissenschaft</td>\n",
       "      <td>in das Getriebe des gesellschaftlichen Lebens</td>\n",
       "      <td>B</td>\n",
       "      <td>Bruch, semantische Erweiterung, nicht ersetzba...</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wohlfahrt hätte, wäre ein absurdum. Dies komm...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>fast die ganze Außenwelt lückenlos umspannen</td>\n",
       "      <td>des Menschen Interessen</td>\n",
       "      <td>B</td>\n",
       "      <td>Irritation, unersetzlich, Bedeutungserweiterun...</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>NaN</td>\n",
       "      <td>137\\tAm einfachsten und am schnellsten wird de...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>['der gordische Knoten', 'dem Schwerte', 'durc...</td>\n",
       "      <td>['dieser Frage', 'des \"frommen Glaubens\"', '',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>622.0</td>\n",
       "      <td>['Haeckel_Lebenswunder_Stufe2_B.xmi', 'Haeckel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>NaN</td>\n",
       "      <td>188\\tIndem ich meine Leser einlade, mit mir da...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>['der engen Eingangspforte', 'Eintrittskarte',...</td>\n",
       "      <td>['das weite Gebiet der monistischen Philosophi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>628.0</td>\n",
       "      <td>['Haeckel_Lebenswunder_Stufe2_B.xmi', 'Haeckel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hat aber die Abstammungslehre recht, so muß si...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>['keine Violine', 'keine Violine da ist']</td>\n",
       "      <td>['lückenlosen Übergänge', 'um sie zum Ausdruck...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>639.0</td>\n",
       "      <td>['Haecker_Stufe2_T.xmi', 'Haecker_Stufe2_P.xmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Lassen sich nach dem zuletztGesagten die Organ...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>['Damm', 'durchbricht', 'Damm']</td>\n",
       "      <td>['naturwissenschaftlicher Forschnngsgrundsätze...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>640.0</td>\n",
       "      <td>['Haecker_Stufe2_T.xmi', 'Haecker_Stufe2_T.xmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Die Amerikaner folgern, da sie alle Rohmateria...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>['einer turmhohen Mauer', 'turmhohen Mauer']</td>\n",
       "      <td>['Schutzzöllen', 'von Schutzzöllen']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>654.0</td>\n",
       "      <td>['Schalk_Stufe2_B_5.xmi', 'Schalk_Stufe2_T_5.x...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>906 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Seite                                         Textstelle Metapher?  \\\n",
       "0      NaN   Bei Beobachtung solchen moralischen Wertes ka...  Metapher   \n",
       "2      NaN   Diese wolle die bittere Auslese, ohne die auc...  Metapher   \n",
       "3      NaN   Wenn es dem Verfasser gelungen ist, ein gesic...  Metapher   \n",
       "7      NaN   Man kann vielmehr in das Getriebe des gesells...  Metapher   \n",
       "9      NaN   Wohlfahrt hätte, wäre ein absurdum. Dies komm...  Metapher   \n",
       "...    ...                                                ...       ...   \n",
       "3188   NaN  137\\tAm einfachsten und am schnellsten wird de...  Metapher   \n",
       "3194   NaN  188\\tIndem ich meine Leser einlade, mit mir da...  Metapher   \n",
       "3205   NaN  Hat aber die Abstammungslehre recht, so muß si...  Metapher   \n",
       "3206   NaN  Lassen sich nach dem zuletztGesagten die Organ...  Metapher   \n",
       "3220   NaN  Die Amerikaner folgern, da sie alle Rohmateria...  Metapher   \n",
       "\n",
       "                                                  Fokus  \\\n",
       "0                                  das Horoskop stellen   \n",
       "2                                               bittere   \n",
       "3     ein gesichertes Fundament und die ersten Pfeil...   \n",
       "7                              Leuchte der Wissenschaft   \n",
       "9          fast die ganze Außenwelt lückenlos umspannen   \n",
       "...                                                 ...   \n",
       "3188  ['der gordische Knoten', 'dem Schwerte', 'durc...   \n",
       "3194  ['der engen Eingangspforte', 'Eintrittskarte',...   \n",
       "3205          ['keine Violine', 'keine Violine da ist']   \n",
       "3206                    ['Damm', 'durchbricht', 'Damm']   \n",
       "3220       ['einer turmhohen Mauer', 'turmhohen Mauer']   \n",
       "\n",
       "                                                 Rahmen Stärkegrad (A, B, C)  \\\n",
       "0                                          einer Nation                    B   \n",
       "2                                               Auslese                    A   \n",
       "3     die Lösung der hier zur Bearbeitung gestellten...                    A   \n",
       "7         in das Getriebe des gesellschaftlichen Lebens                    B   \n",
       "9                               des Menschen Interessen                    B   \n",
       "...                                                 ...                  ...   \n",
       "3188  ['dieser Frage', 'des \"frommen Glaubens\"', '',...                  NaN   \n",
       "3194  ['das weite Gebiet der monistischen Philosophi...                  NaN   \n",
       "3205  ['lückenlosen Übergänge', 'um sie zum Ausdruck...                  NaN   \n",
       "3206  ['naturwissenschaftlicher Forschnngsgrundsätze...                  NaN   \n",
       "3220               ['Schutzzöllen', 'von Schutzzöllen']                  NaN   \n",
       "\n",
       "                                   Begründung/Kommentar     Annotator  \\\n",
       "0     Horoskop stellen - bezogen auf Nationen ist da...             B   \n",
       "2     Unauffällig, aber doch metaphorisch: Dass eine...             B   \n",
       "3     Bruch, Fokus nicht ohne Bedeutungsverlust erse...             B   \n",
       "7     Bruch, semantische Erweiterung, nicht ersetzba...             B   \n",
       "9     Irritation, unersetzlich, Bedeutungserweiterun...             B   \n",
       "...                                                 ...           ...   \n",
       "3188                                                NaN  GoldStandard   \n",
       "3194                                                NaN  GoldStandard   \n",
       "3205                                                NaN  GoldStandard   \n",
       "3206                                                NaN  GoldStandard   \n",
       "3220                                                NaN  GoldStandard   \n",
       "\n",
       "     Unnamed: 2 Semantikerweiterung? Unersetzlich? sprachlich irregulär?  \\\n",
       "0           NaN                  NaN           NaN                   NaN   \n",
       "2           NaN                  NaN           NaN                   NaN   \n",
       "3           NaN                  NaN           NaN                   NaN   \n",
       "7           NaN                  NaN           NaN                   NaN   \n",
       "9           NaN                  NaN           NaN                   NaN   \n",
       "...         ...                  ...           ...                   ...   \n",
       "3188        NaN                  NaN           NaN                   NaN   \n",
       "3194        NaN                  NaN           NaN                   NaN   \n",
       "3205        NaN                  NaN           NaN                   NaN   \n",
       "3206        NaN                  NaN           NaN                   NaN   \n",
       "3220        NaN                  NaN           NaN                   NaN   \n",
       "\n",
       "     pointiert?  Unnamed: 0                                           Filename  \n",
       "0           NaN         NaN                                                NaN  \n",
       "2           NaN         NaN                                                NaN  \n",
       "3           NaN         NaN                                                NaN  \n",
       "7           NaN         NaN                                                NaN  \n",
       "9           NaN         NaN                                                NaN  \n",
       "...         ...         ...                                                ...  \n",
       "3188        NaN       622.0  ['Haeckel_Lebenswunder_Stufe2_B.xmi', 'Haeckel...  \n",
       "3194        NaN       628.0  ['Haeckel_Lebenswunder_Stufe2_B.xmi', 'Haeckel...  \n",
       "3205        NaN       639.0  ['Haecker_Stufe2_T.xmi', 'Haecker_Stufe2_P.xmi...  \n",
       "3206        NaN       640.0  ['Haecker_Stufe2_T.xmi', 'Haecker_Stufe2_T.xmi...  \n",
       "3220        NaN       654.0  ['Schalk_Stufe2_B_5.xmi', 'Schalk_Stufe2_T_5.x...  \n",
       "\n",
       "[906 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading annotated data of the gold standard\n",
    "gold_standard_df = pd.read_csv(ROOT_PATH + DATA_PATH + '/Annotationen-Stufe-2-GoldStandard.csv')\n",
    "\n",
    "# Loading annotated data for non-metaphors\n",
    "no_metaphor_df = pd.read_csv(ROOT_PATH + DATA_PATH + '/NoMetaphor.csv', index_col=0)\n",
    "\n",
    "# Combine all data into one DataFrame\n",
    "raw_df = pd.concat([raw_df, gold_standard_df, no_metaphor_df], axis=0,ignore_index=True)\n",
    "\n",
    "# If the related parameter is set to true and a valid Deepl API Key is present, oversampling will be performed on the raw_df and this oversampled_data_df will be saved as .csv file\n",
    "if (oversample_dataframe and deepl_auth_key != 'DEEPL_AUTH_KEY'):\n",
    "  oversampled_data_df = oversample_dataframe(gold_standard_df)\n",
    "  oversampled_data_df.to_csv('goldstandard_dataframe_oversampled.csv', index=False)\n",
    "\n",
    "display(raw_df[raw_df['Metapher?'] == 'Metapher'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c1e780a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Textstelle</th>\n",
       "      <th>Metapher?</th>\n",
       "      <th>Fokus</th>\n",
       "      <th>Rahmen</th>\n",
       "      <th>Annotator</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Synonym (aus Englischem)</th>\n",
       "      <th>Synonym (aus Spanischem)</th>\n",
       "      <th>Synonym (aus Tchechischem)</th>\n",
       "      <th>Synonym (aus Polnischem)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bei Beobachtung solchen moralischen Wertes ka...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>Matzat_Stufe2_Vergleich.tsv</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>das 19. Jahrhundert schließt in dieser Hinsic...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>Matzat_Stufe2_Vergleich.tsv</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Auch er ist ein genauer Kenner gerade der röm...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>Matzat_Stufe2_Vergleich.tsv</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Wenn sonach das Zweckprinzip auf der ganzen L...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>Matzat_Stufe2_Vergleich.tsv</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>oder aber uns dieser unaufhaltsam daherrollen...</td>\n",
       "      <td>Metapher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>Matzat_Stufe2_Vergleich.tsv</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>652</td>\n",
       "      <td>Der Grund dieser Handlungsweise ist wohl ein d...</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>['Schalk_Stufe2_B_5.xmi', 'Schalk_Stufe2_T_5.x...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>653</td>\n",
       "      <td>In ähnlicher Weise sollen noch mehrere andere ...</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>['Schalk_Stufe2_B_5.xmi', 'Schalk_Stufe2_T_5.x...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>655</td>\n",
       "      <td>Sie könne bei ihrer jetzigen großen Kraft und ...</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>['Schalk_Stufe2_B_5.xmi', 'Schalk_Stufe2_T_5.x...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>656</td>\n",
       "      <td>Schwarze Flecken von Habgier, Raubsucht, Unger...</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>['Schalk_Stufe2_B_5.xmi', 'Schalk_Stufe2_T_5.x...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>657</td>\n",
       "      <td>Die Organisation, wie das natürlich ist, geht ...</td>\n",
       "      <td>Metaphernkandidat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldStandard</td>\n",
       "      <td>['Schalk_Stufe2_B_5.xmi', 'Schalk_Stufe2_T_5.x...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>658 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                         Textstelle  \\\n",
       "0             0   Bei Beobachtung solchen moralischen Wertes ka...   \n",
       "2             2   das 19. Jahrhundert schließt in dieser Hinsic...   \n",
       "12           12   Auch er ist ein genauer Kenner gerade der röm...   \n",
       "15           15   Wenn sonach das Zweckprinzip auf der ganzen L...   \n",
       "18           18   oder aber uns dieser unaufhaltsam daherrollen...   \n",
       "..          ...                                                ...   \n",
       "652         652  Der Grund dieser Handlungsweise ist wohl ein d...   \n",
       "653         653  In ähnlicher Weise sollen noch mehrere andere ...   \n",
       "655         655  Sie könne bei ihrer jetzigen großen Kraft und ...   \n",
       "656         656  Schwarze Flecken von Habgier, Raubsucht, Unger...   \n",
       "657         657  Die Organisation, wie das natürlich ist, geht ...   \n",
       "\n",
       "             Metapher? Fokus Rahmen     Annotator  \\\n",
       "0             Metapher   NaN    NaN  GoldStandard   \n",
       "2             Metapher   NaN    NaN  GoldStandard   \n",
       "12            Metapher   NaN    NaN  GoldStandard   \n",
       "15            Metapher   NaN    NaN  GoldStandard   \n",
       "18            Metapher   NaN    NaN  GoldStandard   \n",
       "..                 ...   ...    ...           ...   \n",
       "652  Metaphernkandidat   NaN    NaN  GoldStandard   \n",
       "653  Metaphernkandidat   NaN    NaN  GoldStandard   \n",
       "655  Metaphernkandidat   NaN    NaN  GoldStandard   \n",
       "656  Metaphernkandidat   NaN    NaN  GoldStandard   \n",
       "657  Metaphernkandidat   NaN    NaN  GoldStandard   \n",
       "\n",
       "                                              Filename  \\\n",
       "0                          Matzat_Stufe2_Vergleich.tsv   \n",
       "2                          Matzat_Stufe2_Vergleich.tsv   \n",
       "12                         Matzat_Stufe2_Vergleich.tsv   \n",
       "15                         Matzat_Stufe2_Vergleich.tsv   \n",
       "18                         Matzat_Stufe2_Vergleich.tsv   \n",
       "..                                                 ...   \n",
       "652  ['Schalk_Stufe2_B_5.xmi', 'Schalk_Stufe2_T_5.x...   \n",
       "653  ['Schalk_Stufe2_B_5.xmi', 'Schalk_Stufe2_T_5.x...   \n",
       "655  ['Schalk_Stufe2_B_5.xmi', 'Schalk_Stufe2_T_5.x...   \n",
       "656  ['Schalk_Stufe2_B_5.xmi', 'Schalk_Stufe2_T_5.x...   \n",
       "657  ['Schalk_Stufe2_B_5.xmi', 'Schalk_Stufe2_T_5.x...   \n",
       "\n",
       "    Synonym (aus Englischem) Synonym (aus Spanischem)  \\\n",
       "0                                                       \n",
       "2                                                       \n",
       "12                                                      \n",
       "15                                                      \n",
       "18                                                      \n",
       "..                       ...                      ...   \n",
       "652                      NaN                      NaN   \n",
       "653                      NaN                      NaN   \n",
       "655                      NaN                      NaN   \n",
       "656                      NaN                      NaN   \n",
       "657                      NaN                      NaN   \n",
       "\n",
       "    Synonym (aus Tchechischem) Synonym (aus Polnischem)  \n",
       "0                                                        \n",
       "2                                                        \n",
       "12                                                       \n",
       "15                                                       \n",
       "18                                                       \n",
       "..                         ...                      ...  \n",
       "652                        NaN                      NaN  \n",
       "653                        NaN                      NaN  \n",
       "655                        NaN                      NaN  \n",
       "656                        NaN                      NaN  \n",
       "657                        NaN                      NaN  \n",
       "\n",
       "[658 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41459e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "oversampled_data_df[\"Synonym (aus Polnischem)\"].str.len().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45821348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotators = ['T', 'A', 'P', 'B', 'K']\n",
    "def get_class_data_by_annotator(annotator = 'all', class_name = 'Metapher', size= 0)-> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Gets the class data by annotator\n",
    "  :param annotator: the specific annotator to data from. If 'all', data from all annotators is returned\n",
    "  :param class_name: The name of the class which should be returned\n",
    "  :param size: The size of the returned dataframe. If size=0, all data is returned\n",
    "  :return df: A dataframe of given size, containing all data of a given annotator and class\n",
    "  \"\"\"  \n",
    "  annotators = set(raw_df['Annotator'].tolist())\n",
    "  if annotator == 'all':\n",
    "    df = raw_df.loc[(raw_df['Annotator'].isin(['T', 'A', 'P', 'B', 'K', 'GoldStandard', 'X']) ) & (raw_df['Metapher?'] == class_name)]\n",
    "  elif annotator not in annotators:\n",
    "    raise Exception('The given Annotator is not found')\n",
    "  else:\n",
    "    df = raw_df.loc[(raw_df['Annotator'] == annotator) & (raw_df['Metapher?'] == class_name)]\n",
    "\n",
    "  # shuffle rows\n",
    "  df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "  if size != 0:\n",
    "    df = df.head(size)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7342d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(train_texts, test_texts, train_labels, test_labels, strategy=\"most_frequent\"):\n",
    "  \"\"\"\n",
    "  Returns the Accuracy, Average Macro F1 score and individual Macro F1 score for each class for a given set of train and test data with a given \n",
    "  :param train_texts: The train set\n",
    "  :param test_texts: The test set\n",
    "  :param train_labels: The train labels\n",
    "  :param test_labels: The test labels\n",
    "  :param strategy: The strategy for the classifier (for example 'most_frequent', 'stratified')\n",
    "  :return acc: The accuracy of the baseline classifier on the given data with the given strategy\n",
    "  :return macro_f1: The average Macro F1 score of the baseline classifier on the given data with the given strategy\n",
    "  :return per_class_macro_f1: The individual class Macro F1 scores of the baseline classifier on the given data with the given strategy\n",
    "  \"\"\"  \n",
    "  dummy_clf = DummyClassifier(strategy=strategy)\n",
    "  dummy_clf.fit(train_texts, train_labels)\n",
    "  prediction = dummy_clf.predict(test_texts)\n",
    "  # calculate accuracy using sklearn's function\n",
    "  test_labels = test_labels.to_numpy(dtype=int)\n",
    "  prediction = prediction.astype(int)\n",
    "  acc = accuracy_score(test_labels, prediction)\n",
    "  macro_f1 = f1_score(test_labels, prediction, average='macro')\n",
    "  per_class_macro_f1 = f1_score(test_labels, prediction, average=None).tolist()\n",
    "\n",
    "  display(\"-----------------------------------\")\n",
    "  display(\"Baseline using strategy=\", strategy)\n",
    "  display(\"Accuracy:\", acc)\n",
    "  display(\"Macro F1:\", macro_f1)\n",
    "  display(\"Per Class Macro F1:\", per_class_macro_f1)\n",
    "  display(\"-----------------------------------\")\n",
    "\n",
    "  return acc, macro_f1, per_class_macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8288402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_tokenizer(model_type='redewiedergabe', smote=False):\n",
    "  \"\"\"\n",
    "  Returns an individual model and corresponding tokenizer \n",
    "  :param model_type: The type of model to load\n",
    "  :param smote: The test set\n",
    "  :return model: The average Macro F1 score of the baseline classifier on the given data with the given strategy\n",
    "  :return tokenizer: The individual class Macro F1 scores of the baseline classifier on the given data with the given strategy\n",
    "  \"\"\"    \n",
    "\n",
    "  if model_type == 'fine_tuned':\n",
    "    if smote>0:\n",
    "      model = BertForSequenceClassificationSMOTE.from_pretrained(ROOT_PATH + MODEL_PATH, cache_dir=None, num_labels=3)\n",
    "    else:\n",
    "      model = BertForSequenceClassification.from_pretrained(ROOT_PATH + MODEL_PATH, cache_dir=None, num_labels=3)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ROOT_PATH + MODEL_PATH)\n",
    "  elif model_type == 'intermediate_task_vua':\n",
    "    if smote>0:\n",
    "      model = BertForSequenceClassificationSMOTE.from_pretrained(ROOT_PATH + '/intermediate-task-vua/model', num_labels=3, ignore_mismatched_sizes=True)\n",
    "    else:\n",
    "      model = BertForSequenceClassification.from_pretrained(ROOT_PATH + '/intermediate-task-vua/model', num_labels=3, ignore_mismatched_sizes=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ROOT_PATH + '/intermediate-task-trofi-vua/model')\n",
    "  elif model_type == 'intermediate_task_trofi':\n",
    "    if smote>0:\n",
    "      model = BertForSequenceClassificationSMOTE.from_pretrained(ROOT_PATH + '/intermediate-task-trofi/model', num_labels=3, ignore_mismatched_sizes=True)\n",
    "    else:\n",
    "      model = BertForSequenceClassification.from_pretrained(ROOT_PATH + '/intermediate-task-trofi/model', num_labels=3, ignore_mismatched_sizes=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ROOT_PATH + '/intermediate-task-trofi/model')\n",
    "  elif model_type == 'bert_base_multilingual_cased':\n",
    "    if smote:\n",
    "      model = BertForSequenceClassificationSMOTE.from_pretrained(\"bert-base-multilingual-cased\", cache_dir=None, num_labels=3)\n",
    "    else:\n",
    "      model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", cache_dir=None, num_labels=3)\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "  elif model_type == 'redewiedergabe':\n",
    "    if smote:\n",
    "      model = BertForSequenceClassificationSMOTE.from_pretrained(\"redewiedergabe/bert-base-historical-german-rw-cased\", cache_dir=None, num_labels=3)\n",
    "    else:\n",
    "      model = BertForSequenceClassification.from_pretrained(\"redewiedergabe/bert-base-historical-german-rw-cased\", cache_dir=None, num_labels=3)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"redewiedergabe/bert-base-historical-german-rw-cased\")\n",
    "  return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a49393",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaphorDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    The dataset class for metaphors\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        \"\"\"\n",
    "        Initializes the dataset\n",
    "        :param encodings: The type of model to load\n",
    "        :param labels: Boolean value to toggle SMOTE\n",
    "        \"\"\"    \n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns an individual item by id\n",
    "        :param idx: The id of the item to return\n",
    "        :return item: The chosen item\n",
    "        \"\"\"    \n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Helper to return the size of the dataset\n",
    "        :return lenght: the size of the dataset\n",
    "        \"\"\"    \n",
    "        return len(self.labels)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Computes accuracy, macro_f1 score and individual macro f1 per class for a given prediction\n",
    "    :param pred: The prediction\n",
    "    :return dict: A dictionary containing accuracy, macro_f1 score and individual macro f1 per class\n",
    "    \"\"\"    \n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # calculate accuracy using sklearn's function\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average='macro')\n",
    "    per_class_macro_f1 = f1_score(labels, preds, average=None).tolist()\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'macro_f1': macro_f1,\n",
    "        'per_class_macro_f1': per_class_macro_f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8cfefcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(path, results, annotator):\n",
    "  \"\"\"\n",
    "  Saves the results of a training to a given path\n",
    "  :param path: The path to save to\n",
    "  :param results: The results to save\n",
    "  :param annotator: The annotator of this particular result\n",
    "  \"\"\"    \n",
    "  print(\"Saving results to\", path)\n",
    "  with open(path + '/results_'+annotator+'.csv', 'w') as csv_file:  \n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in results.items():\n",
    "       writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72b60756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_labels(df):  \n",
    "  \"\"\"\n",
    "  Returns the labels as numerical values: '0' for Non-Metaphors, '1' for Metaphor candidates and '2' for Metaphors\n",
    "  :param df: The dataframe to change\n",
    "  :return df: The changed dataframe, containing labels as numerical values\n",
    "  \"\"\" \n",
    "  df.loc[df['Metapher?'] == 'Nein', 'Metapher?'] = 0\n",
    "  df.loc[df['Metapher?'] == 'Metaphernkandidat', 'Metapher?'] = 1\n",
    "  df.loc[df['Metapher?'] == 'Unklar', 'Metapher?'] = 1\n",
    "  df.loc[df['Metapher?'] == 'Grenzfall', 'Metapher?'] = 1\n",
    "  df.loc[df['Metapher?'] == 'Metapher', 'Metapher?'] = 2\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ed26586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oversamples(entry):\n",
    "  \"\"\"\n",
    "  Returns the oversampling entries corresponding to a specific entry\n",
    "  :param entry: The entry to get the oversampling data to\n",
    "  :return oversamples: The oversampling data to the given entry\n",
    "  \"\"\" \n",
    "  oversamples = pd.DataFrame()\n",
    "  textstelle = entry['Textstelle']\n",
    "  # getting oversampling data from gold standard\n",
    "  gold_standard_entry = get_numerical_labels(gold_standard_df[gold_standard_df['Textstelle']==textstelle])\n",
    "  for language in [\"Synonym (aus Englischem)\", \"Synonym (aus Spanischem)\", \"Synonym (aus Tchechischem)\", \"Synonym (aus Polnischem)\"]:\n",
    "    oversamples= oversamples.append(gold_standard_entry)\n",
    "    oversamples.iloc[-1]['Textstelle'] = oversamples.iloc[-1][language]\n",
    "  return oversamples\n",
    "\n",
    "def generate_oversampled_data(df, size):\n",
    "  \"\"\"\n",
    "  Generates oversampled data to given data with a specific size by randomly selecting from all oversampling data\n",
    "  :param df: The data for which oversampling data should be generated\n",
    "  :param size: The size of the generated data\n",
    "  :return new_samples: The oversampling data to the given data with given size\n",
    "  \"\"\"   \n",
    "  new_samples = pd.DataFrame()\n",
    "  for index, row in df.iterrows():\n",
    "    new_samples= new_samples.append(get_oversamples(row))\n",
    "  return new_samples.sample(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97b3367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_statistics(df):\n",
    "    \"\"\"\n",
    "    Generates a statistic of a given dataframe\n",
    "    :param df: The data for which a statistic should be generated\n",
    "    :return statistic: The statistic of the given dataframe\n",
    "    \"\"\"   \n",
    "    return \"non-metaphors: {} ({:.0%}), metaphor candidates: {} ({:.0%}), metaphors: {} ({:.0%})\".format(df['Metapher?'].value_counts()[0],df['Metapher?'].value_counts()[0]/df['Metapher?'].value_counts().sum(),df['Metapher?'].value_counts()[1],df['Metapher?'].value_counts()[1]/df['Metapher?'].value_counts().sum(),df['Metapher?'].value_counts()[2],df['Metapher?'].value_counts()[2]/df['Metapher?'].value_counts().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48453d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the maximum sentence length\n",
    "max_length = 512\n",
    "# setting the default stärkegrad of the raw data\n",
    "raw_df = set_default_staerkegrad_df(raw_df)\n",
    "\n",
    "def train(annotator, model_type, epochs=3, folds=10, oversampling=True, smote=0, path='/'):\n",
    "  \"\"\"\n",
    "  Training a given model with k-fold cross-validation and various oversampling strategies\n",
    "  The resulting metrics are saved as CSV to a given path\n",
    "  :param annotator: The annotator on whose data to train\n",
    "  :param model_type: The type of model to use\n",
    "  :param epochs: The amount of epochs to train\n",
    "  :param folds: The amount of folds to use for k-fold cross validation\n",
    "  :param oversampling: Boolean to set true if oversampling should be used\n",
    "  :param smote: K value for smote. If set to 0, smote is deactivated\n",
    "  :param path: The path to save the results to\n",
    "  :return evaluation_results: The results of the evaluation of the trained model\n",
    "  \"\"\"     \n",
    "  print(\"Training with data from annotator\", annotator)\n",
    "  metaphor_candidates = get_class_data_by_annotator(annotator, class_name='Metaphernkandidat')\n",
    "  metaphors = get_class_data_by_annotator(annotator, class_name='Metapher')\n",
    "  # Using only the same amount of non-metaphors as metaphor candidates\n",
    "  not_metaphors = get_class_data_by_annotator(class_name='Nein', size=len(metaphor_candidates))\n",
    "\n",
    "  df = pd.concat([metaphors, metaphor_candidates, not_metaphors])\n",
    "  # Shuffle the rows  \n",
    "  df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "  # Data Statistics\n",
    "  samples = len(metaphor_candidates)+len(metaphors)+len(not_metaphors)\n",
    "  print(\"Number of individual classes in data:\", df_statistics(df))\n",
    "\n",
    "  # changing the labels to numerical values\n",
    "  df = get_numerical_labels(df)\n",
    "\n",
    "  baseline_accuracy = []\n",
    "  baseline_macro_f1 = []\n",
    "  baseline_per_class_macro_f1 = []\n",
    "\n",
    "  evaluation_accuracy = []\n",
    "  evaluation_macro_f1 = []\n",
    "  evaluation_per_class_macro_f1 = []\n",
    "\n",
    "\n",
    "  # K-Fold Cross Validation\n",
    "  kf = StratifiedKFold(n_splits=folds, shuffle=False)\n",
    "  i = 0\n",
    "  for train_index, test_index in kf.split(df['Textstelle'], df['Metapher?'].to_list()):\n",
    "    \n",
    "    model, tokenizer = load_model_tokenizer(model_type=model_type, smote=smote)\n",
    "    i += 1\n",
    "    display(\"-----------------------------------\")\n",
    "    print(\"Annotator\", annotator, \"| Fold #\", i)\n",
    "\n",
    "    train_samples = df.iloc[train_index.tolist()]\n",
    "    test_samples = df.iloc[test_index.tolist()]\n",
    "\n",
    "    train_metaphors = train_samples[train_samples[\"Metapher?\"] == 2]\n",
    "    test_metaphors = test_samples[test_samples[\"Metapher?\"] == 2]\n",
    "\n",
    "    #print(\"Number of individual classes in train:\", df_statistics(train_samples))\n",
    "    #print(\"Number of individual classes in test:\", df_statistics(test_samples))\n",
    "\n",
    "    if oversampling:\n",
    "      # add oversampled metaphors\n",
    "      oversampled__train_samples = generate_oversampled_data(df=train_metaphors, size=(train_samples['Metapher?'].value_counts()[0]-train_samples['Metapher?'].value_counts()[2]))\n",
    "\n",
    "      train_samples = pd.concat([train_samples, oversampled__train_samples]) \n",
    "\n",
    "    #print(\"Number of individual classes in train (after oversampling):\", df_statistics(train_samples))\n",
    "    #print(\"Number of individual classes in test (after oversampling):\", df_statistics(test_samples))\n",
    "\n",
    "\n",
    "    train_texts = train_samples['Textstelle']\n",
    "    test_texts = test_samples['Textstelle']\n",
    "    train_labels = train_samples['Metapher?']\n",
    "    test_labels = test_samples['Metapher?']\n",
    "\n",
    "    # Baseline\n",
    "    b_acc, b_macro_f1, b_per_class_macro_f1 = baseline(train_texts, test_texts, train_labels, test_labels, strategy=\"stratified\") # use 'most_frequent' 'stratified' or 'uniform'\n",
    "\n",
    "    baseline_accuracy.append(b_acc)\n",
    "    baseline_macro_f1.append(b_macro_f1)\n",
    "    baseline_per_class_macro_f1.append(b_per_class_macro_f1)\n",
    "    \n",
    "    train_encodings = tokenizer(train_texts.to_list(), truncation=True, padding=True, max_length=max_length)\n",
    "    test_encodings = tokenizer(test_texts.to_list(), truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "\n",
    "    # convert our tokenized data into a torch Dataset\n",
    "    train_dataset = MetaphorDataset(train_encodings, train_labels.tolist())\n",
    "    test_dataset = MetaphorDataset(test_encodings, test_labels.tolist())\n",
    "\n",
    "    #if smote>0:\n",
    "    #  get_smote_points(model, train_samples['Metapher?'].value_counts()[2], train_dataset, test_dataset)\n",
    "    #  model.smote_factor = int(train_samples['Metapher?'].value_counts()[0]/train_samples['Metapher?'].value_counts()[2])-1\n",
    "    #  model.smote_k = smote\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',          # output directory\n",
    "        num_train_epochs=epochs,              # total number of training epochs\n",
    "        per_device_train_batch_size=8,  # batch size per device during training\n",
    "        per_device_eval_batch_size=20,   # batch size for evaluation\n",
    "        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,               # strength of weight decay\n",
    "        logging_dir='./logs',            # directory for storing logs\n",
    "        load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "        # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "        save_total_limit=1,\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        evaluation_strategy=\"epoch\",     # evaluate each `logging_steps`\n",
    "        metric_for_best_model=\"macro_f1\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,                         # the instantiated Transformers model to be trained\n",
    "        args=training_args,                  # training arguments, defined above\n",
    "        train_dataset=train_dataset,         # training dataset\n",
    "        eval_dataset=test_dataset,          # evaluation dataset\n",
    "        compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    #print(\"SMOTE created\", model.smote_counter, \"synthetic data points\")\n",
    "\n",
    "    evaluation = trainer.evaluate()\n",
    "\n",
    "    evaluation_accuracy.append(evaluation['eval_accuracy'])\n",
    "    evaluation_macro_f1.append(evaluation['eval_macro_f1'])\n",
    "    evaluation_per_class_macro_f1.append(evaluation['eval_per_class_macro_f1'])\n",
    "  \n",
    "  evaluation_results = {\n",
    "    \"baseline_accuracy\": baseline_accuracy,\n",
    "    \"baseline_macro_f1\": baseline_macro_f1,\n",
    "    \"baseline_per_class_macro_f1\": baseline_per_class_macro_f1,\n",
    "    \"evaluation_accuracy\": evaluation_accuracy,\n",
    "    \"evaluation_macro_f1\": evaluation_macro_f1,\n",
    "    \"evaluation_per_class_macro_f1\": evaluation_per_class_macro_f1\n",
    "  }\n",
    "\n",
    "  try:\n",
    "    save_results(path,evaluation_results, annotator)\n",
    "  except:\n",
    "    print(\"There seems to be a problem with Google Drive. The CSV could not be saved. Results are only stored locally in results[annotator].\")\n",
    "  return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4751b415",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fynn/Uni/DL4NLP/results/runs/2022-07-29-10:15:49 | redewiedergabe | EPOCHS 3 | FOLDS 10 | OVERSAMPLING\n",
      "/Users/fynn/Uni/DL4NLP/results/runs/2022-07-29-10:15:49 | redewiedergabe | EPOCHS 3 | FOLDS 10 | OVERSAMPLING\n",
      "Settings saved to /Users/fynn/Uni/DL4NLP/results/runs/2022-07-29-10:15:49 | redewiedergabe | EPOCHS 3 | FOLDS 10 | OVERSAMPLING\n",
      "Training with data from annotator GoldStandard\n",
      "Number of individual classes in data: non-metaphors: 529 (45%), metaphor candidates: 529 (45%), metaphors: 129 (11%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'-----------------------------------'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotator GoldStandard | Fold # 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j4/qmf6qmvd1gv0nctgx3m6jm3r0000gn/T/ipykernel_26536/3459997705.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  oversamples= oversamples.append(gold_standard_entry)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Synonym (aus Englischem)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Synonym (aus Englischem)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m   foldernames\u001b[38;5;241m.\u001b[39mappend(folder_name)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m annotator \u001b[38;5;129;01min\u001b[39;00m ANNOTATORS: \n\u001b[0;32m---> 35\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannotator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFOLDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moversampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOVERSAMPLING\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRUN_PATH\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     36\u001b[0m   current_results[annotator] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m     37\u001b[0m   foldernames\u001b[38;5;241m.\u001b[39mappend(folder_name)\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(annotator, model_type, epochs, folds, oversampling, smote, path)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m#print(\"Number of individual classes in train:\", df_statistics(train_samples))\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#print(\"Number of individual classes in test:\", df_statistics(test_samples))\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m oversampling:\n\u001b[1;32m     65\u001b[0m   \u001b[38;5;66;03m# add oversampled metaphors\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m   oversampled__train_samples \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_oversampled_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_metaphors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMetapher?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mtrain_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMetapher?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m   train_samples \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([train_samples, oversampled__train_samples]) \n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#print(\"Number of individual classes in train (after oversampling):\", df_statistics(train_samples))\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m#print(\"Number of individual classes in test (after oversampling):\", df_statistics(test_samples))\u001b[39;00m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mgenerate_oversampled_data\u001b[0;34m(df, size)\u001b[0m\n\u001b[1;32m     23\u001b[0m new_samples \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 25\u001b[0m   new_samples\u001b[38;5;241m=\u001b[39m new_samples\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_oversamples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_samples\u001b[38;5;241m.\u001b[39msample(size)\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mget_oversamples\u001b[0;34m(entry)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m language \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSynonym (aus Englischem)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSynonym (aus Spanischem)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSynonym (aus Tchechischem)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSynonym (aus Polnischem)\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     12\u001b[0m   oversamples\u001b[38;5;241m=\u001b[39m oversamples\u001b[38;5;241m.\u001b[39mappend(gold_standard_entry)\n\u001b[0;32m---> 13\u001b[0m   oversamples\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTextstelle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43moversamples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m oversamples\n",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/Uni/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Synonym (aus Englischem)'"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Parameters for Training\n",
    "ANNOTATORS = [\n",
    "    #'T',\n",
    "    #'A',\n",
    "    #'P',\n",
    "    #'B', \n",
    "    #'K',\n",
    "    'GoldStandard'] # specify the annotators on which to train. Possible annotators = ['T', 'A', 'P', 'B', 'K', 'GoldStandard']\n",
    "EPOCHS=3\n",
    "FOLDS=10\n",
    "OVERSAMPLING = True\n",
    "SMOTE = 0 #This defines the factor k for k-nearest-neighbors used by SMOTE. SMOTE is off if set to 0.\n",
    "COMMENT='Unbalanced for all annotators.'\n",
    "#########################\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "current_results = {}\n",
    "SAVE_RESULTS = True\n",
    "foldernames = [] \n",
    "\n",
    "models = ['redewiedergabe'] # possible model_types are 'redewiedergabe', 'bert_base_multilingual_cased', 'fine_tuned', 'intermediate_task_trofi' and 'intermediate_task_vua'\n",
    "for model in models: \n",
    "  folder_name = datetime.today().strftime('%Y-%m-%d-%H:%M:%S') + \" | \" + model + \" | EPOCHS \"+ str(EPOCHS)+ \" | FOLDS \"+ str(FOLDS)+ ((\" | SMOTE (K=\"+str(SMOTE)+\")\") if SMOTE>0 else \"\") + ((\" | OVERSAMPLING\") if OVERSAMPLING>0 else \"\")\n",
    "  RUN_PATH = ROOT_PATH + RESULTS_PATH + '/runs/' + folder_name\n",
    "  print(RUN_PATH)\n",
    "\n",
    "  if SAVE_RESULTS:\n",
    "    print(RUN_PATH)\n",
    "    !mkdir \"$RUN_PATH\"\n",
    "    save_settings(RUN_PATH, ANNOTATORS, EPOCHS, FOLDS, model, OVERSAMPLING, SMOTE, COMMENT)\n",
    "    foldernames.append(folder_name)\n",
    "\n",
    "  for annotator in ANNOTATORS: \n",
    "    result = train(annotator, model, epochs=EPOCHS, folds=FOLDS, oversampling=OVERSAMPLING, smote=SMOTE, path=RUN_PATH) \n",
    "    current_results[annotator] = result\n",
    "    foldernames.append(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6746fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d0664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_csv(path):\n",
    "  \"\"\"\n",
    "  Loads all CSV data for plotting\n",
    "  :param path: The path to load from\n",
    "  :return df: The loaded data as a dataframe\n",
    "  \"\"\"\n",
    "  df = pd.read_csv(path, names=['measure', 'results'], header=None)\n",
    "  annotator = path[-5]\n",
    "  \n",
    "  df['results'] = df['results'].apply(lambda x: np.array(json.loads(x)))\n",
    "  df['annotator'] = annotator\n",
    "  return df\n",
    "\n",
    "# Plotting with multiple annotators\n",
    "def open_csv_annotators(path, annotator):\n",
    "  \"\"\"\n",
    "  Loads all CSV data for plotting for individual annotators\n",
    "  :param path: The path to load from\n",
    "  :return df: The loaded data as a dataframe\n",
    "  \"\"\"\n",
    "  print(path)\n",
    "  try:\n",
    "    df = pd.read_csv(path, names=['measure', 'results'], header=None)\n",
    "    df['results'] = df['results'].apply(lambda x: np.fromstring(x[1:-1], sep=', '))\n",
    "    df['annotator'] = annotator\n",
    "    annotator_names.append(annotator)\n",
    "  except:\n",
    "    df = pd.DataFrame()\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b212bf2b",
   "metadata": {},
   "source": [
    "We can see that the Bert Model is unable to identify metaphors if it is not trained on backtranslations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
